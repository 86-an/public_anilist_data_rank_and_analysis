import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from pathlib import Path

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AniList åŸºç¤çµ±è¨ˆ",
    page_icon="ğŸ“Š", 
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def load_anime_data():
    """ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                a.anilist_id, a.title_romaji, a.title_native, a.format, 
                a.season, a.seasonYear, a.favorites, a.meanScore, 
                a.popularity, a.source
            FROM anime a
            WHERE a.title_romaji IS NOT NULL
            ORDER BY a.meanScore DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def get_genres_data(db_path):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        conn = sqlite3.connect(str(db_path))
        query = "SELECT DISTINCT genre_name FROM genres ORDER BY genre_name"
        cursor = conn.cursor()
        cursor.execute(query)
        genres = [row[0] for row in cursor.fetchall()]
        conn.close()
        return genres
    except sqlite3.Error as e:
        st.error(f"âŒ ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return []

@st.cache_data
def load_character_data():
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                c.chara_id, c.chara_name, c.favorites as char_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format, a.source
            FROM characters c
            JOIN anime a ON c.anilist_id = a.anilist_id
            WHERE c.chara_name IS NOT NULL
            ORDER BY c.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_voiceactor_data():
    """å£°å„ªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                v.voiceactor_id, v.voiceactor_name, v.favorites as va_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format, a.source,
                vb.voiceactor_count, vb.count_per_year
            FROM voiceactors v
            JOIN anime a ON v.anilist_id = a.anilist_id
            LEFT JOIN voiceactor_basic vb ON v.voiceactor_id = vb.voiceactor_id
            WHERE v.voiceactor_name IS NOT NULL
            ORDER BY v.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… å£°å„ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_staff_data():
    """ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                s.staff_id, s.staff_name, s.role, s.favorites as staff_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format, a.source,
                sb.staff_count, sb.count_per_year
            FROM staff s
            JOIN anime a ON s.anilist_id = a.anilist_id
            LEFT JOIN staff_basic sb ON s.staff_id = sb.staff_id
            WHERE s.staff_name IS NOT NULL
            ORDER BY s.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_studios_data():
    """ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                s.studios_id, s.studios_name,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites as anime_favorites, 
                a.meanScore, a.format, a.source,
                sb.studios_count, sb.count_per_year
            FROM studios s
            JOIN anime a ON s.anilist_id = a.anilist_id
            LEFT JOIN studios_basic sb ON s.studios_id = sb.studios_id
            WHERE s.studios_name IS NOT NULL
            ORDER BY sb.studios_count DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        
        # studios_statsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        stats_query = """
            SELECT 
                studios_id,
                stat_type,
                total,
                avg_value
            FROM studios_stats
        """
        stats_data = pd.read_sql_query(stats_query, conn)
        conn.close()
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ”ãƒœãƒƒãƒˆã—ã¦å„studios_idã«å¯¾ã—ã¦æ¨ªå±•é–‹
        if not stats_data.empty:
            stats_pivot = stats_data.pivot_table(
                index='studios_id',
                columns='stat_type',
                values=['total', 'avg_value'],
                aggfunc='first'
            )
            
            # ã‚«ãƒ©ãƒ åã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
            stats_pivot.columns = ['_'.join(col).strip() for col in stats_pivot.columns.values]
            stats_pivot = stats_pivot.reset_index()
            
            # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
            data = data.merge(stats_pivot, on='studios_id', how='left')
        
        st.success(f"âœ… ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_genre_data():
    """ã‚¢ãƒ‹ãƒ¡ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                g.genre_name,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format, a.source
            FROM genres g
            JOIN anime a ON g.anilist_id = a.anilist_id
            WHERE g.genre_name IS NOT NULL AND a.title_romaji IS NOT NULL
            ORDER BY a.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_source_data():
    """ã‚¢ãƒ‹ãƒ¡åŸä½œãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                a.source,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format
            FROM anime a
            WHERE a.source IS NOT NULL AND a.title_romaji IS NOT NULL
            ORDER BY a.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… åŸä½œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_studio_data():
    """ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±å«ã‚€ï¼‰"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        
        # ã‚¹ã‚¿ã‚¸ã‚ªã¨ã‚¢ãƒ‹ãƒ¡ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        query_studio = """
            SELECT 
                s.studios_name,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites, 
                a.meanScore, a.popularity, a.format, a.source
            FROM studios s
            JOIN anime a ON s.anilist_id = a.anilist_id
            WHERE s.studios_name IS NOT NULL AND a.title_romaji IS NOT NULL
            ORDER BY a.favorites DESC NULLS LAST
        """
        studio_data = pd.read_sql_query(query_studio, conn)
        
        # ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã‚’å–å¾—
        query_genres = """
            SELECT anilist_id, genre_name
            FROM genres
            WHERE genre_name IS NOT NULL
        """
        genres_data = pd.read_sql_query(query_genres, conn)
        conn.close()
        
        # ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é›†ç´„ï¼ˆè¤‡æ•°ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§çµåˆï¼‰
        genres_agg = genres_data.groupby('anilist_id')['genre_name'].apply(lambda x: ', '.join(sorted(set(x)))).reset_index()
        genres_agg.columns = ['anilist_id', 'genres']
        
        # ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã¨ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ãƒãƒ¼ã‚¸
        data = studio_data.merge(genres_agg, on='anilist_id', how='left')
        data['genres'] = data['genres'].fillna('Unknown')
        
        st.success(f"âœ… ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_manga_data():
    """ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'manga_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ manga_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                m.anilist_id, m.title_romaji, m.title_native, m.format,
                m.seasonYear, m.meanScore, m.favorites, m.popularity
            FROM manga m
            WHERE m.title_romaji IS NOT NULL
            ORDER BY m.meanScore DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_manga_genre_data():
    """ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'manga_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ manga_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                g.genre_name,
                m.anilist_id, m.title_romaji, m.title_native, 
                m.seasonYear, m.favorites, 
                m.meanScore, m.popularity, m.format
            FROM genres g
            JOIN manga m ON g.anilist_id = m.anilist_id
            WHERE g.genre_name IS NOT NULL AND m.title_romaji IS NOT NULL
            ORDER BY m.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_manga_character_data():
    """ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'manga_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ manga_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                c.chara_id, c.chara_name, c.favorites as char_favorites,
                m.anilist_id, m.title_romaji, m.title_native, 
                m.seasonYear, m.favorites, 
                m.meanScore, m.popularity, m.format, m.source
            FROM characters c
            JOIN manga m ON c.anilist_id = m.anilist_id
            WHERE c.chara_name IS NOT NULL
            ORDER BY c.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_manga_staff_data():
    """ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'manga_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ manga_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # staffãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='staff'")
        if not cursor.fetchone():
            conn.close()
            st.warning("âš ï¸ manga_data.dbã«staffãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            return None
        
        # staff_basic_enhancedãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='staff_basic_enhanced'")
        has_enhanced = cursor.fetchone() is not None
        
        if has_enhanced:
            query = """
                SELECT 
                    s.staff_id, s.staff_name, s.role,
                    m.anilist_id, m.title_romaji, m.title_native, 
                    m.seasonYear, m.favorites as manga_favorites, 
                    m.meanScore, m.format, m.source,
                    sbe.favorites as staff_favorites,
                    sbe.total_count as staff_count,
                    sbe.count_per_year
                FROM staff s
                JOIN manga m ON s.anilist_id = m.anilist_id
                LEFT JOIN staff_basic_enhanced sbe ON s.staff_id = sbe.staff_id
                WHERE s.staff_name IS NOT NULL
                ORDER BY sbe.favorites DESC NULLS LAST
            """
        else:
            query = """
                SELECT 
                    s.staff_id, s.staff_name, s.role, s.favorites as staff_favorites,
                    m.anilist_id, m.title_romaji, m.title_native, 
                    m.seasonYear, m.favorites as manga_favorites, 
                    m.meanScore, m.format, m.source
                FROM staff s
                JOIN manga m ON s.anilist_id = m.anilist_id
                WHERE s.staff_name IS NOT NULL
                ORDER BY s.favorites DESC NULLS LAST
            """
        
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_unique_values(data, column):
    """æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—"""
    if column in data.columns:
        unique_vals = data[column].dropna().unique()
        # æ•°å€¤ã®å ´åˆã¯é™é †ã§ã‚½ãƒ¼ãƒˆã€æ–‡å­—åˆ—ã®å ´åˆã¯æ˜‡é †ã§ã‚½ãƒ¼ãƒˆ
        if pd.api.types.is_numeric_dtype(unique_vals):
            return sorted(unique_vals, reverse=True)
        else:
            return sorted(unique_vals)
    return []

def create_decade_filter(data, selected_decade, year_column='seasonYear'):
    """å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
    
    Args:
        data: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        selected_decade: é¸æŠã•ã‚ŒãŸå¹´ä»£ï¼ˆ'å…¨æœŸé–“', '1900å¹´ä»£', '2000å¹´ä»£', '2010å¹´ä»£', '2020å¹´ä»£'ï¼‰
        year_column: å¹´åº¦ã‚’è¡¨ã™åˆ—åï¼ˆ'seasonYear' or 'seasonYear'ï¼‰
    
    Returns:
        ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    if selected_decade == "å…¨æœŸé–“" or year_column not in data.columns:
        return data
    
    # å¹´ä»£ã®ç¯„å›²ã‚’å®šç¾©
    decade_ranges = {
        "1900å¹´ä»£": (1900, 1999),
        "2000å¹´ä»£": (2000, 2009),
        "2010å¹´ä»£": (2010, 2019),
        "2020å¹´ä»£": (2020, 2029)
    }
    
    if selected_decade in decade_ranges:
        start_year, end_year = decade_ranges[selected_decade]
        return data[(data[year_column] >= start_year) & (data[year_column] <= end_year)]
    
    return data

def calculate_statistics_by_period(data, metric_col='favorites', year_column='seasonYear'):
    """æœŸé–“åˆ¥çµ±è¨ˆã‚’è¨ˆç®—ã™ã‚‹æ±ç”¨é–¢æ•°
    
    Args:
        data: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        metric_col: çµ±è¨ˆã‚’è¨ˆç®—ã™ã‚‹åˆ—å
        year_column: å¹´åº¦ã‚’è¡¨ã™åˆ—åï¼ˆ'seasonYear' or 'seasonYear'ï¼‰
    
    Returns:
        dict: {
            'overall': å…¨æœŸé–“çµ±è¨ˆã®dict,
            'period_total': é¸æŠæœŸé–“åˆè¨ˆçµ±è¨ˆã®dict,
            'yearly': å¹´åˆ¥çµ±è¨ˆã®DataFrame,
            'decade': å¹´ä»£åˆ¥çµ±è¨ˆã®DataFrame
        }
    """
    if metric_col not in data.columns or year_column not in data.columns:
        return None
    
    # ãƒ¡ãƒˆãƒªãƒƒã‚¯åˆ—ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    metric_data = data[metric_col].dropna()
    
    # å…¨æœŸé–“çµ±è¨ˆï¼ˆ10é …ç›®ï¼‰
    overall_stats = {
        'åˆè¨ˆ': float(metric_data.sum()),
        'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_data),
        'æœ€å¤§': float(metric_data.max()),
        'æœ€å°': float(metric_data.min()),
        'å¹³å‡': float(metric_data.mean()),
        'ä¸­å¤®å€¤': float(metric_data.median()),
        '1/4åˆ†ä½': float(metric_data.quantile(0.25)),
        '3/4åˆ†ä½': float(metric_data.quantile(0.75))
    }
    
    # æ¨™æº–åå·®ã¨åˆ†æ•£ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ãŒ2ä»¥ä¸Šã®å ´åˆã®ã¿è¨ˆç®—ï¼‰
    if len(metric_data) > 1:
        overall_stats['æ¨™æº–åå·®'] = float(metric_data.std())
        overall_stats['åˆ†æ•£'] = float(metric_data.var())
    else:
        overall_stats['æ¨™æº–åå·®'] = 0.0
        overall_stats['åˆ†æ•£'] = 0.0
    
    # é¸æŠæœŸé–“åˆè¨ˆçµ±è¨ˆï¼ˆå…¨æœŸé–“ã¨åŒã˜ï¼‰
    period_total_stats = overall_stats.copy()
    
    # å¹´åˆ¥çµ±è¨ˆï¼ˆ10é …ç›®ï¼‰
    yearly_data = []
    for year in sorted(data[year_column].dropna().unique(), reverse=True):
        year_data = data[data[year_column] == year]
        year_metric = year_data[metric_col].dropna()
        
        if len(year_metric) == 0:
            continue
        
        year_stats = {
            'å¹´åº¦': int(year),
            'åˆè¨ˆ': float(year_metric.sum()),
            'ã‚«ã‚¦ãƒ³ãƒˆ': len(year_metric),
            'æœ€å¤§': float(year_metric.max()),
            'æœ€å°': float(year_metric.min()),
            'å¹³å‡': float(year_metric.mean()),
            'ä¸­å¤®å€¤': float(year_metric.median()),
            '1/4åˆ†ä½': float(year_metric.quantile(0.25)),
            '3/4åˆ†ä½': float(year_metric.quantile(0.75))
        }
        
        # æ¨™æº–åå·®ã¨åˆ†æ•£
        if len(year_metric) > 1:
            year_stats['æ¨™æº–åå·®'] = float(year_metric.std())
            year_stats['åˆ†æ•£'] = float(year_metric.var())
        else:
            year_stats['æ¨™æº–åå·®'] = 0.0
            year_stats['åˆ†æ•£'] = 0.0
        
        yearly_data.append(year_stats)
    
    yearly_df = pd.DataFrame(yearly_data)
    
    # å¹´ä»£åˆ¥çµ±è¨ˆï¼ˆ10é …ç›®ï¼‰
    decade_data = []
    decade_ranges = {
        "1900å¹´ä»£": (1900, 1999),
        "2000å¹´ä»£": (2000, 2009),
        "2010å¹´ä»£": (2010, 2019),
        "2020å¹´ä»£": (2020, 2029)
    }
    
    for decade_name, (start_year, end_year) in decade_ranges.items():
        decade_filtered = data[(data[year_column] >= start_year) & (data[year_column] <= end_year)]
        decade_metric = decade_filtered[metric_col].dropna()
        
        if len(decade_metric) == 0:
            continue
        
        decade_stats = {
            'å¹´ä»£': decade_name,
            'åˆè¨ˆ': float(decade_metric.sum()),
            'ã‚«ã‚¦ãƒ³ãƒˆ': len(decade_metric),
            'æœ€å¤§': float(decade_metric.max()),
            'æœ€å°': float(decade_metric.min()),
            'å¹³å‡': float(decade_metric.mean()),
            'ä¸­å¤®å€¤': float(decade_metric.median()),
            '1/4åˆ†ä½': float(decade_metric.quantile(0.25)),
            '3/4åˆ†ä½': float(decade_metric.quantile(0.75))
        }
        
        # æ¨™æº–åå·®ã¨åˆ†æ•£
        if len(decade_metric) > 1:
            decade_stats['æ¨™æº–åå·®'] = float(decade_metric.std())
            decade_stats['åˆ†æ•£'] = float(decade_metric.var())
        else:
            decade_stats['æ¨™æº–åå·®'] = 0.0
            decade_stats['åˆ†æ•£'] = 0.0
        
        decade_data.append(decade_stats)
    
    decade_df = pd.DataFrame(decade_data)
    
    return {
        'overall': overall_stats,
        'period_total': period_total_stats,
        'yearly': yearly_df,
        'decade': decade_df
    }

def filter_data(data, filters, db_path=None):
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿"""
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre'] and filters['genre'] != "å…¨ã¦" and db_path:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                # è©²å½“ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ã®ã‚¢ãƒ‹ãƒ¡ãŒãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and value != "å…¨ã¦" and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    return filtered_data

def show_studios_ranking_tab(data):
    """ã‚¹ã‚¿ã‚¸ã‚ªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ¢ ã‚¹ã‚¿ã‚¸ã‚ª ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="studios_rank_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="studios_rank_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="studios_rank_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="studios_rank_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="studios_rank_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="studios_rank_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ã‚¹ã‚¿ã‚¸ã‚ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['studios_id', 'anime_favorites'], ascending=[True, False]).groupby('studios_id').first().reset_index()
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¿ã‚¸ã‚ªã®ã‚«ã‚¦ãƒ³ãƒˆæ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values('studios_count', ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    display_columns = [
        'studios_name', 'title_native', 'seasonYear', 'season', 
        'studios_count', 'count_per_year', 'anime_favorites', 'meanScore'
    ]
    
    # stat_typeåˆ¥ã®ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    stat_columns = [col for col in sorted_data.columns if col.startswith('total_') or col.startswith('avg_value_')]
    display_columns.extend(stat_columns)
    
    available_columns = [col for col in display_columns if col in sorted_data.columns]
    display_data = sorted_data[available_columns].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    column_mapping = {
        'studios_name': 'ã‚¹ã‚¿ã‚¸ã‚ªå',
        'title_native': 'ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«',
        'seasonYear': 'å¹´åº¦',
        'season': 'å­£ç¯€',
        'studios_count': 'ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'count_per_year': 'ã‚¹ã‚¿ã‚¸ã‚ªå¹´åº¦å¹³å‡å›æ•°',
        'anime_favorites': 'ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°',
        'meanScore': 'ã‚¢ãƒ‹ãƒ¡å¹³å‡ã‚¹ã‚³ã‚¢',
        'total_anime_favorites': 'anime_favoritesåˆè¨ˆ',
        'avg_value_anime_favorites': 'anime_favoriteså¹³å‡',
        'total_anime_meanScore': 'anime_meanScoreåˆè¨ˆ',
        'avg_value_anime_meanScore': 'anime_meanScoreå¹³å‡'
    }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    numeric_columns = ['studios_count', 'count_per_year', 'anime_favorites', 'meanScore'] + stat_columns
    for col in numeric_columns:
        if col in display_data.columns:
            display_data[col] = display_data[col].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ã‚¹ã‚¿ã‚¸ã‚ª")
        
        top_n = min(10, len(sorted_data))
        top_data = sorted_data.head(top_n)
        
        fig = px.bar(
            top_data,
            x='studios_count',
            y='studios_name',
            orientation='h',
            title=f"ãƒˆãƒƒãƒ—{top_n}ã‚¹ã‚¿ã‚¸ã‚ªï¼ˆä½œå“æ•°é †ï¼‰",
            labels={
                'studios_count': 'ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°',
                'studios_name': 'ã‚¹ã‚¿ã‚¸ã‚ªå'
            },
            hover_data={
                'studios_name': True,
                'title_native': True,
                'studios_count': True,
                'count_per_year': ':.2f',
                'anime_favorites': True,
                'meanScore': ':.1f'
            }
        )
        
    return filtered_data

def show_studios_statistics_tab(data):
    """ã‚¹ã‚¿ã‚¸ã‚ªåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“Š ã‚¹ã‚¿ã‚¸ã‚ª åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãã‚¹ã‚¿ã‚¸ã‚ªã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="studios_stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="studios_stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="studios_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="studios_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="studios_stats_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="studios_stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ã‚¸ã‚ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['studios_id', 'anime_favorites'], ascending=[True, False]).groupby('studios_id').first().reset_index()
    
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆ{len(filtered_data):,}ã‚¹ã‚¿ã‚¸ã‚ªï¼‰")
    
    # è¡¨1: studios_basicãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨1: ã‚¹ã‚¿ã‚¸ã‚ªåŸºæœ¬çµ±è¨ˆï¼ˆstudios_basicï¼‰")
    
    basic_stats_dict = {}
    
    # studios_countçµ±è¨ˆ
    if 'studios_count' in filtered_data.columns:
        studios_count_data = filtered_data['studios_count'].dropna()
        if len(studios_count_data) > 0:
            basic_stats_dict['ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°'] = {
                'åˆè¨ˆ': f"{studios_count_data.sum():,.0f}",
                'æœ€å¤§å€¤': f"{studios_count_data.max():,.0f}",
                'æœ€å°å€¤': f"{studios_count_data.min():,.0f}",
                'å¹³å‡å€¤': f"{studios_count_data.mean():,.2f}",
                'ä¸­å¤®å€¤': f"{studios_count_data.median():,.2f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{studios_count_data.quantile(0.25):,.2f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{studios_count_data.quantile(0.75):,.2f}"
            }
    
    # first_yearçµ±è¨ˆ
    if 'first_year' in filtered_data.columns:
        first_year_data = filtered_data['first_year'].dropna()
        if len(first_year_data) > 0:
            basic_stats_dict['åˆå‡ºå¹´'] = {
                'åˆè¨ˆ': '-',
                'æœ€å¤§å€¤': f"{int(first_year_data.max())}",
                'æœ€å°å€¤': f"{int(first_year_data.min())}",
                'å¹³å‡å€¤': f"{first_year_data.mean():,.1f}",
                'ä¸­å¤®å€¤': f"{first_year_data.median():,.1f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{first_year_data.quantile(0.25):,.1f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{first_year_data.quantile(0.75):,.1f}"
            }
    
    # year_countçµ±è¨ˆ
    if 'year_count' in filtered_data.columns:
        year_count_data = filtered_data['year_count'].dropna()
        if len(year_count_data) > 0:
            basic_stats_dict['æ´»å‹•å¹´æ•°'] = {
                'åˆè¨ˆ': f"{year_count_data.sum():,.0f}",
                'æœ€å¤§å€¤': f"{year_count_data.max():,.0f}",
                'æœ€å°å€¤': f"{year_count_data.min():,.0f}",
                'å¹³å‡å€¤': f"{year_count_data.mean():,.2f}",
                'ä¸­å¤®å€¤': f"{year_count_data.median():,.2f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{year_count_data.quantile(0.25):,.2f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{year_count_data.quantile(0.75):,.2f}"
            }
    
    # count_per_yearçµ±è¨ˆ
    if 'count_per_year' in filtered_data.columns:
        count_per_year_data = filtered_data['count_per_year'].dropna()
        if len(count_per_year_data) > 0:
            basic_stats_dict['å¹´å¹³å‡ã‚«ã‚¦ãƒ³ãƒˆæ•°'] = {
                'åˆè¨ˆ': f"{count_per_year_data.sum():,.2f}",
                'æœ€å¤§å€¤': f"{count_per_year_data.max():,.2f}",
                'æœ€å°å€¤': f"{count_per_year_data.min():,.2f}",
                'å¹³å‡å€¤': f"{count_per_year_data.mean():,.4f}",
                'ä¸­å¤®å€¤': f"{count_per_year_data.median():,.4f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{count_per_year_data.quantile(0.25):,.4f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{count_per_year_data.quantile(0.75):,.4f}"
            }
    
    if basic_stats_dict:
        basic_stats_df = pd.DataFrame(basic_stats_dict)
        st.dataframe(basic_stats_df, width='stretch', height=300)
    else:
        st.info("åŸºæœ¬çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # è¡¨2: studios_statsãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆï¼ˆstat_typeåˆ¥ï¼‰
    st.markdown("### ğŸ“Š è¡¨2: ã‚¹ã‚¿ã‚¸ã‚ªçµ±è¨ˆæƒ…å ±ï¼ˆstudios_statsï¼‰")
    st.markdown("**æ³¨: ã“ã®è¡¨ã¯å…¨ã‚¹ã‚¿ã‚¸ã‚ªã®çµ±è¨ˆå€¤ï¼ˆtotal_anime_favoritesç­‰ï¼‰ã®åˆ†å¸ƒã‚’ç¤ºã—ã¦ã„ã¾ã™**")
    
    # stat_typeåˆ¥ã®ã‚«ãƒ©ãƒ ã‚’æŠ½å‡º
    stat_columns = {}
    for col in filtered_data.columns:
        if col.startswith('total_') or col.startswith('max_value_') or col.startswith('min_value_') or \
           col.startswith('avg_value_') or col.startswith('median_value_') or \
           col.startswith('q1_value_') or col.startswith('q3_value_'):
            stat_columns[col] = filtered_data[col]
    
    if stat_columns:
        stats_dict = {}
        
        # anime_favoritesã®çµ±è¨ˆ
        if 'total_anime_favorites' in stat_columns:
            fav_data = filtered_data['total_anime_favorites'].dropna()
            if len(fav_data) > 0:
                stats_dict['anime_favoritesåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{fav_data.sum():,.0f}",
                    'æœ€å¤§å€¤': f"{fav_data.max():,.0f}",
                    'æœ€å°å€¤': f"{fav_data.min():,.0f}",
                    'å¹³å‡å€¤': f"{fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{fav_data.var():,.2f}"
                }
        
        if 'avg_value_anime_favorites' in stat_columns:
            fav_avg_data = filtered_data['avg_value_anime_favorites'].dropna()
            if len(fav_avg_data) > 0:
                stats_dict['anime_favoriteså¹³å‡'] = {
                    'åˆè¨ˆ': f"{fav_avg_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{fav_avg_data.max():,.2f}",
                    'æœ€å°å€¤': f"{fav_avg_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{fav_avg_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{fav_avg_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{fav_avg_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{fav_avg_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{fav_avg_data.std():,.2f}",
                    'åˆ†æ•£': f"{fav_avg_data.var():,.2f}"
                }
        
        # anime_meanScoreã®çµ±è¨ˆ
        if 'total_anime_meanScore' in stat_columns:
            score_data = filtered_data['total_anime_meanScore'].dropna()
            if len(score_data) > 0:
                stats_dict['anime_meanScoreåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{score_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{score_data.max():,.2f}",
                    'æœ€å°å€¤': f"{score_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{score_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{score_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{score_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{score_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{score_data.std():,.2f}",
                    'åˆ†æ•£': f"{score_data.var():,.2f}"
                }
        
        if 'avg_value_anime_meanScore' in stat_columns:
            score_avg_data = filtered_data['avg_value_anime_meanScore'].dropna()
            if len(score_avg_data) > 0:
                stats_dict['anime_meanScoreå¹³å‡'] = {
                    'åˆè¨ˆ': f"{score_avg_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{score_avg_data.max():,.2f}",
                    'æœ€å°å€¤': f"{score_avg_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{score_avg_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{score_avg_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{score_avg_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{score_avg_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{score_avg_data.std():,.2f}",
                    'åˆ†æ•£': f"{score_avg_data.var():,.2f}"
                }
        
        if stats_dict:
            stats_df = pd.DataFrame(stats_dict)
            st.dataframe(stats_df, width='stretch', height=400)
        else:
            st.info("çµ±è¨ˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("çµ±è¨ˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # è¡¨3: ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesçµ±è¨ˆã®è©³ç´°åˆ†æ
    st.markdown("---")
    st.markdown("### ğŸ“Š è¡¨3: ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesçµ±è¨ˆã®è©³ç´°åˆ†æ")
    st.markdown("**æ³¨: ã“ã®è¡¨ã¯ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã«é›†è¨ˆã•ã‚ŒãŸanime_favoritesåˆè¨ˆãƒ»å¹³å‡ã®çµ±è¨ˆåˆ†æã§ã™**")
    
    if 'total_anime_favorites' in filtered_data.columns or 'avg_value_anime_favorites' in filtered_data.columns:
        table3_dict = {}
        
        # ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesåˆè¨ˆã®çµ±è¨ˆ
        if 'total_anime_favorites' in filtered_data.columns:
            total_fav_data = filtered_data['total_anime_favorites'].dropna()
            if len(total_fav_data) > 0:
                table3_dict['ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{total_fav_data.sum():,.0f}",
                    'æœ€å¤§å€¤': f"{total_fav_data.max():,.0f}",
                    'æœ€å°å€¤': f"{total_fav_data.min():,.0f}",
                    'å¹³å‡å€¤': f"{total_fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{total_fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{total_fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{total_fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{total_fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{total_fav_data.var():,.2f}"
                }
        
        # ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoriteså¹³å‡ã®çµ±è¨ˆ
        if 'avg_value_anime_favorites' in filtered_data.columns:
            avg_fav_data = filtered_data['avg_value_anime_favorites'].dropna()
            if len(avg_fav_data) > 0:
                table3_dict['ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoriteså¹³å‡'] = {
                    'åˆè¨ˆ': f"{avg_fav_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{avg_fav_data.max():,.2f}",
                    'æœ€å°å€¤': f"{avg_fav_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{avg_fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{avg_fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{avg_fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{avg_fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{avg_fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{avg_fav_data.var():,.2f}"
                }
        
        if table3_dict:
            table3_df = pd.DataFrame(table3_dict)
            st.dataframe(table3_df, width='stretch', height=400)
        else:
            st.info("anime_favoritesçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("anime_favoritesçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒ
    st.markdown("---")
    st.markdown("### ğŸ“Š ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰")
    
    if 'studios_count' in filtered_data.columns:
        count_data = filtered_data['studios_count'].dropna()
        
        if len(count_data) > 0:
            # å¯¾æ•°å¤‰æ›ï¼ˆ0ã®å ´åˆã¯1ã«ç½®ãæ›ãˆï¼‰
            log_count_data = np.log10(count_data.replace(0, 1))
            
            fig = px.histogram(
                x=log_count_data,
                nbins=50,
                title="ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
                labels={'x': 'log10(ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°)', 'y': 'é »åº¦'}
            )
            
            fig.update_layout(
                showlegend=False,
                height=400,
                xaxis_title="log10(ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°)",
                yaxis_title="é »åº¦"
            )
            
            st.plotly_chart(fig, width='stretch')
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(count_data):,}")
            with col2:
                st.metric("å¹³å‡å€¤", f"{count_data.mean():,.2f}")
            with col3:
                st.metric("ä¸­å¤®å€¤", f"{count_data.median():,.2f}")
            with col4:
                st.metric("æ¨™æº–åå·®", f"{count_data.std():,.2f}")
        else:
            st.info("ã‚«ã‚¦ãƒ³ãƒˆæ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("ã‚«ã‚¦ãƒ³ãƒˆæ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def show_voiceactor_statistics_tab(data):
    """å£°å„ªåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º - 3ã¤ã®æŒ‡æ¨™ã®åŸºç¤çµ±è¨ˆ"""
    st.header("ğŸ“Š å£°å„ª åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯å£°å„ªã®ãŠæ°—ã«å…¥ã‚Šæ•°ã€å›æ•°ã€å¹³å‡å›æ•°ã®åŸºç¤çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # å¹´ä»£é¸æŠ
        decade_options = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decade_options, key="va_stats_decade")
    
    with col2:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        format_options = ["å…¨ã¦"] + get_unique_values(data, 'format')
        selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", format_options, key="va_stats_format")
    
    with col3:
        # åŸä½œé¸æŠ
        source_options = ["å…¨ã¦"] + get_unique_values(data, 'source')
        selected_source = st.selectbox("åŸä½œ", source_options, key="va_stats_source")
    
    with col4:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genre_options = ["å…¨ã¦"] + available_genres
        else:
            genre_options = ["å…¨ã¦"]
        selected_genre = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genre_options, key="va_stats_genre")
    
    # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
    data['va_favorites'] = pd.to_numeric(data['va_favorites'], errors='coerce')
    data['voiceactor_count'] = pd.to_numeric(data['voiceactor_count'], errors='coerce')
    data['count_per_year'] = pd.to_numeric(data['count_per_year'], errors='coerce')
    data['seasonYear'] = pd.to_numeric(data['seasonYear'], errors='coerce')
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_genre != "å…¨ã¦":
        filters['genre'] = selected_genre
    
    filtered_data = filter_data(data, filters, db_path=db_path)
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if selected_decade != "å…¨æœŸé–“":
        filtered_data = create_decade_filter(filtered_data, selected_decade, year_column='seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å£°å„ªIDã”ã¨ã«é›†ç´„ï¼ˆé‡è¤‡å‰Šé™¤ï¼‰
    va_aggregated = filtered_data.groupby('voiceactor_id').agg({
        'va_favorites': 'first',
        'voiceactor_count': 'first',
        'count_per_year': 'first'
    }).reset_index()
    
    # 3ã¤ã®æŒ‡æ¨™ã®çµ±è¨ˆè¨ˆç®—
    def calculate_basic_stats(series):
        """åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—"""
        series = series.dropna()
        if len(series) == 0:
            return {}
        
        stats = {
            "åˆè¨ˆ": float(series.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": int(len(series)),
            "æœ€å¤§": float(series.max()),
            "æœ€å°": float(series.min()),
            "å¹³å‡": float(series.mean()),
            "ä¸­å¤®å€¤": float(series.median()),
            "1/4åˆ†ä½": float(series.quantile(0.25)),
            "3/4åˆ†ä½": float(series.quantile(0.75))
        }
        
        if len(series) > 1:
            stats["æ¨™æº–åå·®"] = float(series.std())
            stats["åˆ†æ•£"] = float(series.var())
        else:
            stats["æ¨™æº–åå·®"] = 0.0
            stats["åˆ†æ•£"] = 0.0
        
        return stats
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ å£°å„ªçµ±è¨ˆï¼ˆ{len(va_aggregated):,}åï¼‰")
    
    # è¡¨1: ãŠæ°—ã«å…¥ã‚Šæ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨1: ãŠæ°—ã«å…¥ã‚Šæ•°ã®åŸºç¤çµ±è¨ˆ")
    favorites_stats = calculate_basic_stats(va_aggregated['va_favorites'])
    if favorites_stats:
        favorites_df = pd.DataFrame(
            [(key, value) for key, value in favorites_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "ãŠæ°—ã«å…¥ã‚Šæ•°"]
        )
        st.dataframe(favorites_df, use_container_width=True, height=400)
    else:
        st.warning("ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # è¡¨2: å›æ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨2: å›æ•°ã®åŸºç¤çµ±è¨ˆ")
    count_stats = calculate_basic_stats(va_aggregated['voiceactor_count'])
    if count_stats:
        count_df = pd.DataFrame(
            [(key, value) for key, value in count_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "å›æ•°"]
        )
        st.dataframe(count_df, use_container_width=True, height=400)
    else:
        st.warning("å›æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # è¡¨3: å¹³å‡å›æ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨3: å¹³å‡å›æ•°ã®åŸºç¤çµ±è¨ˆ")
    avg_count_stats = calculate_basic_stats(va_aggregated['count_per_year'])
    if avg_count_stats:
        avg_count_df = pd.DataFrame(
            [(key, value) for key, value in avg_count_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "å¹³å‡å›æ•°"]
        )
        st.dataframe(avg_count_df, use_container_width=True, height=400)
    else:
        st.warning("å¹³å‡å›æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

def show_staff_statistics_tab(data):
    """ã‚¹ã‚¿ãƒƒãƒ•åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º - 3ã¤ã®æŒ‡æ¨™ã®åŸºç¤çµ±è¨ˆ"""
    st.header("ğŸ“Š ã‚¹ã‚¿ãƒƒãƒ• åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯ã‚¹ã‚¿ãƒƒãƒ•ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã€å›æ•°ã€å¹³å‡å›æ•°ã®åŸºç¤çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        # å½¹å‰²é¸æŠ
        role_options = ["å…¨ã¦"] + get_unique_values(data, 'role')
        selected_role = st.selectbox("å½¹å‰²", role_options, key="staff_stats_role")
    
    with col2:
        # å¹´ä»£é¸æŠ
        decade_options = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decade_options, key="staff_stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        format_options = ["å…¨ã¦"] + get_unique_values(data, 'format')
        selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", format_options, key="staff_stats_format")
    
    with col4:
        # åŸä½œé¸æŠ
        source_options = ["å…¨ã¦"] + get_unique_values(data, 'source')
        selected_source = st.selectbox("åŸä½œ", source_options, key="staff_stats_source")
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genre_options = ["å…¨ã¦"] + available_genres
        else:
            genre_options = ["å…¨ã¦"]
        selected_genre = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genre_options, key="staff_stats_genre")
    
    # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
    data['staff_favorites'] = pd.to_numeric(data['staff_favorites'], errors='coerce')
    data['staff_count'] = pd.to_numeric(data['staff_count'], errors='coerce')
    data['count_per_year'] = pd.to_numeric(data['count_per_year'], errors='coerce')
    data['seasonYear'] = pd.to_numeric(data['seasonYear'], errors='coerce')
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    
    # å½¹å‰²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if selected_role != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['role'] == selected_role]
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    filters = {}
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_genre != "å…¨ã¦":
        filters['genre'] = selected_genre
    
    filtered_data = filter_data(filtered_data, filters, db_path=db_path)
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if selected_decade != "å…¨æœŸé–“":
        filtered_data = create_decade_filter(filtered_data, selected_decade, year_column='seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ãƒƒãƒ•IDã”ã¨ã«é›†ç´„ï¼ˆé‡è¤‡å‰Šé™¤ï¼‰
    staff_aggregated = filtered_data.groupby('staff_id').agg({
        'staff_favorites': 'first',
        'staff_count': 'first',
        'count_per_year': 'first'
    }).reset_index()
    
    # 3ã¤ã®æŒ‡æ¨™ã®çµ±è¨ˆè¨ˆç®—
    def calculate_basic_stats(series):
        """åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—"""
        series = series.dropna()
        if len(series) == 0:
            return {}
        
        stats = {
            "åˆè¨ˆ": float(series.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": int(len(series)),
            "æœ€å¤§": float(series.max()),
            "æœ€å°": float(series.min()),
            "å¹³å‡": float(series.mean()),
            "ä¸­å¤®å€¤": float(series.median()),
            "1/4åˆ†ä½": float(series.quantile(0.25)),
            "3/4åˆ†ä½": float(series.quantile(0.75))
        }
        
        if len(series) > 1:
            stats["æ¨™æº–åå·®"] = float(series.std())
            stats["åˆ†æ•£"] = float(series.var())
        else:
            stats["æ¨™æº–åå·®"] = 0.0
            stats["åˆ†æ•£"] = 0.0
        
        return stats
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ ã‚¹ã‚¿ãƒƒãƒ•çµ±è¨ˆï¼ˆ{len(staff_aggregated):,}åï¼‰")
    
    # è¡¨1: ãŠæ°—ã«å…¥ã‚Šæ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨1: ãŠæ°—ã«å…¥ã‚Šæ•°ã®åŸºç¤çµ±è¨ˆ")
    favorites_stats = calculate_basic_stats(staff_aggregated['staff_favorites'])
    if favorites_stats:
        favorites_df = pd.DataFrame(
            [(key, value) for key, value in favorites_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "ãŠæ°—ã«å…¥ã‚Šæ•°"]
        )
        st.dataframe(favorites_df, use_container_width=True, height=400)
    else:
        st.warning("ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # è¡¨2: å›æ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨2: å›æ•°ã®åŸºç¤çµ±è¨ˆ")
    count_stats = calculate_basic_stats(staff_aggregated['staff_count'])
    if count_stats:
        count_df = pd.DataFrame(
            [(key, value) for key, value in count_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "å›æ•°"]
        )
        st.dataframe(count_df, use_container_width=True, height=400)
    else:
        st.warning("å›æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # è¡¨3: å¹³å‡å›æ•°ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨3: å¹³å‡å›æ•°ã®åŸºç¤çµ±è¨ˆ")
    avg_count_stats = calculate_basic_stats(staff_aggregated['count_per_year'])
    if avg_count_stats:
        avg_count_df = pd.DataFrame(
            [(key, value) for key, value in avg_count_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "å¹³å‡å›æ•°"]
        )
        st.dataframe(avg_count_df, use_container_width=True, height=400)
    else:
        st.warning("å¹³å‡å›æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

def calculate_basic_stats(series):
    """åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼‰"""
    series = series.dropna()
    if len(series) == 0:
        return {}
    
    stats = {
        "åˆè¨ˆ": float(series.sum()),
        "ã‚«ã‚¦ãƒ³ãƒˆ": int(len(series)),
        "æœ€å¤§": float(series.max()),
        "æœ€å°": float(series.min()),
        "å¹³å‡": float(series.mean()),
        "ä¸­å¤®å€¤": float(series.median()),
        "1/4åˆ†ä½": float(series.quantile(0.25)),
        "3/4åˆ†ä½": float(series.quantile(0.75))
    }
    
    if len(series) > 1:
        stats["æ¨™æº–åå·®"] = float(series.std())
        stats["åˆ†æ•£"] = float(series.var())
    else:
        stats["æ¨™æº–åå·®"] = 0.0
        stats["åˆ†æ•£"] = 0.0
    
    return stats

def show_character_statistics_tab(data):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®ã¿"""
    st.header("ğŸ“Š ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®å…¨ä½“çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # char_favoritesã‚«ãƒ©ãƒ ã®ç¢ºèªã¨ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
    if 'char_favorites' not in data.columns:
        st.error("char_favoritesã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    data['char_favorites'] = pd.to_numeric(data['char_favorites'], errors='coerce')
    
    # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    char_favorites_data = data['char_favorites'].dropna()
    
    if len(char_favorites_data) == 0:
        st.warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    stats = calculate_basic_stats(char_favorites_data)
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®çµ±è¨ˆï¼ˆ{len(char_favorites_data):,}ä»¶ï¼‰")
    
    # å…¨ä½“çµ±è¨ˆ
    st.markdown("### ğŸ“Š å…¨ä½“çµ±è¨ˆ")
    overall_stats_df = pd.DataFrame(
        [(key, value) for key, value in stats.items()],
        columns=["çµ±è¨ˆé …ç›®", "å€¤"]
    )
    st.dataframe(overall_stats_df, use_container_width=True, height=400)

def show_statistics_tab(data, genre):
    """åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header(f"ğŸ“Š {genre} åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãåŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x),
            key="stats_metric"
        )
    
    with col2:
        # å¹´ä»£é¸æŠ
        decades = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decades, key="stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦ç´ ã‹ã‚‰å‹•çš„ç”Ÿæˆï¼‰
        if 'format' in data.columns:
            unique_formats = sorted(data['format'].dropna().unique())
            formats = ["å…¨ã¦"] + list(unique_formats)
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
    else:
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
    
    # é€šå¸¸ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = filter_data(data, filters, db_path if db_path.exists() else None)
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¢ãƒ‹ãƒ¡ã¯seasonYearã€ãƒãƒ³ã‚¬ã¯seasonYearï¼‰
    year_column = 'seasonYear' 
    filtered_data = create_decade_filter(filtered_data, selected_decade, year_column)
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ ({filtered_count:,}ä»¶)")
    st.markdown(f"**é¸æŠå¹´ä»£**: {selected_decade} | **é¸æŠãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: {selected_format}")
    
    # æœŸé–“åˆ¥çµ±è¨ˆã‚’è¨ˆç®—
    stats_result = calculate_statistics_by_period(filtered_data, selected_metric, year_column)
    
    if stats_result is None:
        st.error(f"é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯{metric_labels.get(selected_metric, selected_metric)}ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return
    
    # 1. å…¨æœŸé–“ã®åŸºç¤çµ±è¨ˆè¡¨
    st.markdown("---")
    st.subheader("ğŸ“Š è¡¨1: å…¨æœŸé–“ã®åŸºç¤çµ±è¨ˆ")
    overall_df = pd.DataFrame(
        [(key, value) for key, value in stats_result['overall'].items()],
        columns=["çµ±è¨ˆé …ç›®", "å€¤"]
    )
    # æ•°å€¤å‹ã«å¤‰æ›
    for col in overall_df.columns:
        if col != "çµ±è¨ˆé …ç›®":
            overall_df[col] = pd.to_numeric(overall_df[col], errors='ignore')
    st.dataframe(overall_df, width='stretch', height=300)
    
    # 2. å¹´ä»£åˆ¥ã®åŸºç¤çµ±è¨ˆï¼ˆå…¨æœŸé–“é¸æŠæ™‚ã®ã¿è¡¨ç¤ºï¼‰
    if selected_decade == "å…¨æœŸé–“" and not stats_result['decade'].empty:
        st.markdown("---")
        st.subheader("ğŸ“Š è¡¨2: å¹´ä»£åˆ¥ã®åŸºç¤çµ±è¨ˆ")
        decade_df = stats_result['decade'].copy()
        # æ•°å€¤å‹ã«å¤‰æ›
        for col in decade_df.columns:
            if col != "å¹´ä»£":
                decade_df[col] = pd.to_numeric(decade_df[col], errors='ignore')
        st.dataframe(decade_df, width='stretch', height=300)
        
        # å¹´ä»£åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•
        st.markdown("---")
        st.subheader("ğŸ“ˆ å¹´ä»£åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•")
        
        # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        plot_data = decade_df.copy()
        
        # é¸æŠæŒ‡æ¨™ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        fig = go.Figure()
        
        # å¹³å‡å€¤ã®æ¨ç§»
        fig.add_trace(go.Scatter(
            x=plot_data['å¹´ä»£'],
            y=plot_data['å¹³å‡'],
            mode='lines+markers',
            name=f'{metric_labels.get(selected_metric, selected_metric)} å¹³å‡',
            line=dict(width=3, color='#1f77b4')
        ))
        
        # ã‚«ã‚¦ãƒ³ãƒˆæ•°ã®æ¨ç§»ï¼ˆå³è»¸ï¼‰
        fig.add_trace(go.Scatter(
            x=plot_data['å¹´ä»£'],
            y=plot_data['ã‚«ã‚¦ãƒ³ãƒˆ'],
            mode='lines+markers',
            name='ã‚¿ã‚¤ãƒˆãƒ«æ•°',
            line=dict(width=2, dash='dash', color='#ff7f0e'),
            yaxis='y2'
        ))
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ2è»¸ï¼‰
        fig.update_layout(
            title=f'å¹´ä»£åˆ¥æ¨ç§» - {metric_labels.get(selected_metric, selected_metric)}',
            xaxis=dict(title='å¹´ä»£'),
            yaxis=dict(
                title=f'{metric_labels.get(selected_metric, selected_metric)}',
                side='left'
            ),
            yaxis2=dict(
                title='ã‚¿ã‚¤ãƒˆãƒ«æ•°',
                overlaying='y',
                side='right'
            ),
            height=500,
            hovermode='x unified',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # 3. é¸æŠæœŸé–“ã®åˆè¨ˆçµ±è¨ˆï¼ˆå…¨æœŸé–“ä»¥å¤–ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    if selected_decade != "å…¨æœŸé–“":
        st.markdown("---")
        st.subheader(f"ğŸ“Š è¡¨2: {selected_decade}ã®åˆè¨ˆçµ±è¨ˆ")
        period_df = pd.DataFrame(
            [(key, value) for key, value in stats_result['period_total'].items()],
            columns=["çµ±è¨ˆé …ç›®", "å€¤"]
        )
        # æ•°å€¤å‹ã«å¤‰æ›
        for col in period_df.columns:
            if col != "çµ±è¨ˆé …ç›®":
                period_df[col] = pd.to_numeric(period_df[col], errors='ignore')
        st.dataframe(period_df, width='stretch', height=300)
    
    # 4. 1å¹´ã”ã¨ã®åŸºç¤çµ±è¨ˆè¡¨ï¼ˆå…¨æœŸé–“ä»¥å¤–ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
    if selected_decade != "å…¨æœŸé–“" and not stats_result['yearly'].empty:
        st.markdown("---")
        st.subheader("ğŸ“Š è¡¨3: 1å¹´ã”ã¨ã®åŸºç¤çµ±è¨ˆ")
        yearly_df = stats_result['yearly'].copy()
        # æ•°å€¤å‹ã«å¤‰æ›
        for col in yearly_df.columns:
            if col != "å¹´åº¦":
                yearly_df[col] = pd.to_numeric(yearly_df[col], errors='ignore')
        st.dataframe(yearly_df, width='stretch', height=400)
        
        # å¹´åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•
        st.markdown("---")
        st.subheader("ğŸ“ˆ å¹´åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•")
        
        # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆå¹´åº¦ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆï¼‰
        plot_data = yearly_df.sort_values('å¹´åº¦')
        
        # é¸æŠæŒ‡æ¨™ã®æ¨ç§»ã‚°ãƒ©ãƒ•
        fig = go.Figure()
        
        # å¹³å‡å€¤ã®æ¨ç§»
        fig.add_trace(go.Scatter(
            x=plot_data['å¹´åº¦'],
            y=plot_data['å¹³å‡'],
            mode='lines+markers',
            name=f'{metric_labels.get(selected_metric, selected_metric)} å¹³å‡',
            line=dict(width=3, color='#1f77b4')
        ))
        
        # ã‚«ã‚¦ãƒ³ãƒˆæ•°ã®æ¨ç§»ï¼ˆå³è»¸ï¼‰
        fig.add_trace(go.Scatter(
            x=plot_data['å¹´åº¦'],
            y=plot_data['ã‚«ã‚¦ãƒ³ãƒˆ'],
            mode='lines+markers',
            name='ã‚¿ã‚¤ãƒˆãƒ«æ•°',
            line=dict(width=2, dash='dash', color='#ff7f0e'),
            yaxis='y2'
        ))
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ2è»¸ï¼‰
        fig.update_layout(
            title=f'{selected_decade}ã®å¹´åˆ¥æ¨ç§» - {metric_labels.get(selected_metric, selected_metric)}',
            xaxis=dict(title='å¹´åº¦'),
            yaxis=dict(
                title=f'{metric_labels.get(selected_metric, selected_metric)}',
                side='left'
            ),
            yaxis2=dict(
                title='ã‚¿ã‚¤ãƒˆãƒ«æ•°',
                overlaying='y',
                side='right'
            ),
            height=500,
            hovermode='x unified',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)


def show_genre_statistics_tab(data):
    """ã‚¸ãƒ£ãƒ³ãƒ«åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ­ ã‚¸ãƒ£ãƒ³ãƒ« åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’ä¸€æ‹¬è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x),
            key="genre_stats_metric"
        )
    
    with col2:
        # å¹´ä»£é¸æŠ
        decades = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decades, key="genre_stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦ç´ ã‹ã‚‰å‹•çš„ç”Ÿæˆï¼‰
        if 'format' in data.columns:
            unique_formats = sorted(data['format'].dropna().unique())
            formats = ["å…¨ã¦"] + list(unique_formats)
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="genre_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    if selected_format != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['format'] == selected_format]
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = create_decade_filter(filtered_data, selected_decade, 'seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—
    if 'genre_name' not in filtered_data.columns:
        st.error("ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    unique_genres = sorted(filtered_data['genre_name'].dropna().unique())
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ")
    st.markdown(f"**é¸æŠå¹´ä»£**: {selected_decade} | **é¸æŠãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: {selected_format} | **ã‚¸ãƒ£ãƒ³ãƒ«æ•°**: {len(unique_genres)}ç¨®é¡")
    
    # å„ã‚¸ãƒ£ãƒ³ãƒ«ã®çµ±è¨ˆã‚’è¨ˆç®—
    genre_stats_list = []
    
    for genre in unique_genres:
        genre_data = filtered_data[filtered_data['genre_name'] == genre].copy()
        
        if genre_data.empty:
            continue
        
        # æŒ‡æ¨™ã®å€¤ã‚’å–å¾—
        metric_values = pd.to_numeric(genre_data[selected_metric], errors='coerce').dropna()
        
        if len(metric_values) == 0:
            continue
        
        # çµ±è¨ˆã‚’è¨ˆç®—
        stats = {
            'ã‚¸ãƒ£ãƒ³ãƒ«': genre,
            'åˆè¨ˆ': metric_values.sum(),
            'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
            'æœ€å¤§': metric_values.max(),
            'æœ€å°': metric_values.min(),
            'å¹³å‡': metric_values.mean(),
            'ä¸­å¤®å€¤': metric_values.median(),
            '1/4åˆ†ä½': metric_values.quantile(0.25),
            '3/4åˆ†ä½': metric_values.quantile(0.75),
            'æ¨™æº–åå·®': metric_values.std(),
            'åˆ†æ•£': metric_values.var()
        }
        genre_stats_list.append(stats)
    
    if not genre_stats_list:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # DataFrameã«å¤‰æ›
    genre_stats_df = pd.DataFrame(genre_stats_list)
    
    # æ•°å€¤å‹ã«å¤‰æ›
    for col in genre_stats_df.columns:
        if col != "ã‚¸ãƒ£ãƒ³ãƒ«":
            genre_stats_df[col] = pd.to_numeric(genre_stats_df[col], errors='ignore')
    
    # 1. å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆè¡¨ï¼ˆå¹³å‡ã§ã‚½ãƒ¼ãƒˆï¼‰
    st.markdown("---")
    st.subheader(f"ğŸ“Š è¡¨1: å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆ ({selected_metric})")
    sorted_df = genre_stats_df.sort_values('å¹³å‡', ascending=False)
    st.dataframe(sorted_df, width='stretch', height=600)
    
    # 2. å¹´ä»£åˆ¥ãƒ»å¹´æ¬¡åˆ¥ã®è©³ç´°çµ±è¨ˆï¼ˆå…¨æœŸé–“ä»¥å¤–ã®å ´åˆï¼‰
    if selected_decade != "å…¨æœŸé–“":
        st.markdown("---")
        st.subheader(f"ğŸ“Š è¡¨2: {selected_decade} - å„å¹´åº¦ã®ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµ±è¨ˆ")
        
        # å¹´åº¦ã”ã¨ã«ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµ±è¨ˆã‚’è¨ˆç®—
        if 'seasonYear' in filtered_data.columns:
            # å¹´åº¦ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆé™é †ï¼‰
            years = sorted(filtered_data['seasonYear'].dropna().unique(), reverse=True)
            
            # å„å¹´åº¦ã®çµ±è¨ˆã‚’è¨ˆç®—
            yearly_genre_stats = []
            
            for year in years:
                year_data = filtered_data[filtered_data['seasonYear'] == year]
                
                for genre in unique_genres:
                    genre_year_data = year_data[year_data['genre_name'] == genre]
                    
                    if genre_year_data.empty:
                        continue
                    
                    metric_values = pd.to_numeric(genre_year_data[selected_metric], errors='coerce').dropna()
                    
                    if len(metric_values) == 0:
                        continue
                    
                    stats = {
                        'å¹´åº¦': int(year),
                        'ã‚¸ãƒ£ãƒ³ãƒ«': genre,
                        'åˆè¨ˆ': metric_values.sum(),
                        'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
                        'æœ€å¤§': metric_values.max(),
                        'æœ€å°': metric_values.min(),
                        'å¹³å‡': metric_values.mean(),
                        'ä¸­å¤®å€¤': metric_values.median(),
                        '1/4åˆ†ä½': metric_values.quantile(0.25),
                        '3/4åˆ†ä½': metric_values.quantile(0.75),
                        'æ¨™æº–åå·®': metric_values.std(),
                        'åˆ†æ•£': metric_values.var()
                    }
                    yearly_genre_stats.append(stats)
            
            if yearly_genre_stats:
                yearly_genre_df = pd.DataFrame(yearly_genre_stats)
                
                # æ•°å€¤å‹ã«å¤‰æ›
                for col in yearly_genre_df.columns:
                    if col not in ["å¹´åº¦", "ã‚¸ãƒ£ãƒ³ãƒ«"]:
                        yearly_genre_df[col] = pd.to_numeric(yearly_genre_df[col], errors='ignore')
                
                st.dataframe(yearly_genre_df, width='stretch', height=600)
                
                # å¹´åº¦åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•ï¼ˆä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®ã¿ï¼‰
                st.markdown("---")
                st.subheader(f"ğŸ“ˆ å¹´åº¦åˆ¥æ¨ç§» - ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«")
                
                # å…¨ä½“ã§å¹³å‡ãŒé«˜ã„ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã‚’å–å¾—
                top_5_genres = sorted_df.head(5)['ã‚¸ãƒ£ãƒ³ãƒ«'].tolist()
                
                # ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                top_5_data = yearly_genre_df[yearly_genre_df['ã‚¸ãƒ£ãƒ³ãƒ«'].isin(top_5_genres)]
                
                if not top_5_data.empty:
                    fig = px.line(
                        top_5_data,
                        x='å¹´åº¦',
                        y='å¹³å‡',
                        color='ã‚¸ãƒ£ãƒ³ãƒ«',
                        markers=True,
                        title=f'{selected_decade} - ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®å¹´åº¦åˆ¥æ¨ç§»',
                        labels={
                            'å¹´åº¦': 'å¹´åº¦',
                            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
                        }
                    )
                    fig.update_layout(height=500, hovermode='x unified')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´åº¦ x ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰
                    st.markdown("---")
                    st.subheader(f"ğŸ”¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— - å¹´åº¦åˆ¥ã‚¸ãƒ£ãƒ³ãƒ«å¹³å‡å€¤")
                    
                    # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                    pivot_data = top_5_data.pivot(index='ã‚¸ãƒ£ãƒ³ãƒ«', columns='å¹´åº¦', values='å¹³å‡')
                    
                    fig_heatmap = px.imshow(
                        pivot_data,
                        labels=dict(x="å¹´åº¦", y="ã‚¸ãƒ£ãƒ³ãƒ«", color=metric_labels.get(selected_metric, selected_metric)),
                        x=pivot_data.columns,
                        y=pivot_data.index,
                        color_continuous_scale='RdYlBu_r',
                        aspect='auto'
                    )
                    fig_heatmap.update_layout(height=400)
                    st.plotly_chart(fig_heatmap, use_container_width=True)
            else:
                st.info("é¸æŠã•ã‚ŒãŸå¹´ä»£ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # 3. ä¸Šä½ãƒ»ä¸‹ä½ã‚¸ãƒ£ãƒ³ãƒ«ã®å¯è¦–åŒ–
    st.markdown("---")
    st.subheader("ğŸ“Š ä¸Šä½ãƒ»ä¸‹ä½ã‚¸ãƒ£ãƒ³ãƒ«æ¯”è¼ƒ")
    
    # ä¸Šä½10ã‚¸ãƒ£ãƒ³ãƒ«
    top_10 = sorted_df.head(10)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"**ä¸Šä½10ã‚¸ãƒ£ãƒ³ãƒ« ({metric_labels.get(selected_metric, selected_metric)})**")
        fig_top = px.bar(
            top_10,
            x='å¹³å‡',
            y='ã‚¸ãƒ£ãƒ³ãƒ«',
            orientation='h',
            text='å¹³å‡',
            color='å¹³å‡',
            color_continuous_scale='Blues'
        )
        fig_top.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_top.update_layout(
            height=400,
            yaxis={'categoryorder': 'total ascending'},
            showlegend=False
        )
        st.plotly_chart(fig_top, use_container_width=True)
    
    with col2:
        # ä¸‹ä½10ã‚¸ãƒ£ãƒ³ãƒ«
        bottom_10 = sorted_df.tail(10)
        st.markdown(f"**ä¸‹ä½10ã‚¸ãƒ£ãƒ³ãƒ« ({metric_labels.get(selected_metric, selected_metric)})**")
        fig_bottom = px.bar(
            bottom_10,
            x='å¹³å‡',
            y='ã‚¸ãƒ£ãƒ³ãƒ«',
            orientation='h',
            text='å¹³å‡',
            color='å¹³å‡',
            color_continuous_scale='Reds'
        )
        fig_bottom.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_bottom.update_layout(
            height=400,
            yaxis={'categoryorder': 'total descending'},
            showlegend=False
        )
        st.plotly_chart(fig_bottom, use_container_width=True)
    
    # 4. å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®å¹³å‡å€¤åˆ†å¸ƒ
    st.markdown("---")
    st.subheader("ğŸ“Š å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åˆ†å¸ƒ")
    
    fig_dist = px.histogram(
        genre_stats_df,
        x='å¹³å‡',
        nbins=30,
        title=f'{metric_labels.get(selected_metric, selected_metric)}ã®åˆ†å¸ƒ',
        labels={'å¹³å‡': metric_labels.get(selected_metric, selected_metric), 'count': 'ã‚¸ãƒ£ãƒ³ãƒ«æ•°'}
    )
    fig_dist.update_layout(height=400, showlegend=False)
    st.plotly_chart(fig_dist, use_container_width=True)
    
    # 5. ã‚«ã‚¦ãƒ³ãƒˆ vs å¹³å‡ã®æ•£å¸ƒå›³
    st.markdown("---")
    st.subheader("ğŸ“Š ã‚¿ã‚¤ãƒˆãƒ«æ•° vs å¹³å‡å€¤")
    
    fig_scatter = px.scatter(
        genre_stats_df,
        x='ã‚«ã‚¦ãƒ³ãƒˆ',
        y='å¹³å‡',
        text='ã‚¸ãƒ£ãƒ³ãƒ«',
        size='ã‚«ã‚¦ãƒ³ãƒˆ',
        color='å¹³å‡',
        color_continuous_scale='Viridis',
        labels={
            'ã‚«ã‚¦ãƒ³ãƒˆ': 'ã‚¿ã‚¤ãƒˆãƒ«æ•°',
            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
        },
        title=f'ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã‚¿ã‚¤ãƒˆãƒ«æ•°ã¨{metric_labels.get(selected_metric, selected_metric)}ã®é–¢ä¿‚'
    )
    fig_scatter.update_traces(textposition='top center')
    fig_scatter.update_layout(height=500)
    st.plotly_chart(fig_scatter, use_container_width=True)


def show_manga_character_statistics_tab(data):
    """ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®ã¿"""
    st.header("ğŸ“š ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®å…¨ä½“çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # char_favoritesã‚«ãƒ©ãƒ ã®ç¢ºèªã¨ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
    if 'char_favorites' not in data.columns:
        st.error("char_favoritesã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    data['char_favorites'] = pd.to_numeric(data['char_favorites'], errors='coerce')
    
    # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    char_favorites_data = data['char_favorites'].dropna()
    
    if len(char_favorites_data) == 0:
        st.warning("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    stats = calculate_basic_stats(char_favorites_data)
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®çµ±è¨ˆï¼ˆ{len(char_favorites_data):,}ä»¶ï¼‰")
    
    # å…¨ä½“çµ±è¨ˆ
    st.markdown("### ğŸ“Š å…¨ä½“çµ±è¨ˆ")
    overall_stats_df = pd.DataFrame(
        [(key, value) for key, value in stats.items()],
        columns=["çµ±è¨ˆé …ç›®", "å€¤"]
    )
    st.dataframe(overall_stats_df, use_container_width=True, height=400)

def show_manga_staff_statistics_tab(data):
    """ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ•åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“š ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ• åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯ã‚¹ã‚¿ãƒƒãƒ•ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã€å›æ•°ã€å¹³å‡å›æ•°ã®åŸºç¤çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # å½¹å‰²é¸æŠ
        role_options = ["å…¨ã¦"] + sorted(data['role'].dropna().unique().tolist())
        selected_role = st.selectbox("å½¹å‰²", role_options, key="manga_staff_stats_role")
    
    with col2:
        # å¹´ä»£é¸æŠ
        decade_options = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decade_options, key="manga_staff_stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        format_options = ["å…¨ã¦"] + get_unique_values(data, 'format')
        selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", format_options, key="manga_staff_stats_format")
    
    with col4:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        if db_path.exists():
            try:
                conn = sqlite3.connect(str(db_path))
                cursor = conn.cursor()
                cursor.execute("SELECT DISTINCT genre_name FROM genres ORDER BY genre_name")
                available_genres = [row[0] for row in cursor.fetchall()]
                conn.close()
                genre_options = ["å…¨ã¦"] + available_genres
            except:
                genre_options = ["å…¨ã¦"]
        else:
            genre_options = ["å…¨ã¦"]
        selected_genre = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genre_options, key="manga_staff_stats_genre")
    
    # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›
    data['staff_favorites'] = pd.to_numeric(data['staff_favorites'], errors='coerce')
    data['seasonYear'] = pd.to_numeric(data['seasonYear'], errors='coerce')
    
    # staff_count ã¨ count_per_year ã®å‡¦ç†
    if 'staff_count' in data.columns:
        data['staff_count'] = pd.to_numeric(data['staff_count'], errors='coerce')
    if 'count_per_year' in data.columns:
        data['count_per_year'] = pd.to_numeric(data['count_per_year'], errors='coerce')
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    
    if selected_role != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['role'] == selected_role]
    
    if selected_format != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['format'] == selected_format]
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if selected_genre != "å…¨ã¦":
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (selected_genre,))
            genre_manga_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_manga_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_manga_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    if selected_decade != "å…¨æœŸé–“":
        filtered_data = create_decade_filter(filtered_data, selected_decade, year_column='seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ãƒƒãƒ•IDã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦é›†è¨ˆ
    staff_aggregated = filtered_data.groupby('staff_id').agg({
        'staff_name': 'first',
        'staff_favorites': 'first',
        'staff_count': 'first' if 'staff_count' in filtered_data.columns else lambda x: len(x),
        'count_per_year': 'first' if 'count_per_year' in filtered_data.columns else lambda x: len(x) / max((filtered_data.loc[x.index, 'seasonYear'].max() - filtered_data.loc[x.index, 'seasonYear'].min() + 1), 1)
    }).reset_index()
    
    # staff_count ã¨ count_per_year ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å‡¦ç†
    if 'staff_count' not in data.columns:
        # å„ã‚¹ã‚¿ãƒƒãƒ•ã®å‡ºæ¼”å›æ•°ã‚’è¨ˆç®—
        staff_counts = filtered_data.groupby('staff_id').size().reset_index(name='staff_count')
        staff_aggregated = staff_aggregated.merge(staff_counts, on='staff_id', how='left', suffixes=('', '_new'))
        if 'staff_count_new' in staff_aggregated.columns:
            staff_aggregated['staff_count'] = staff_aggregated['staff_count_new']
            staff_aggregated.drop('staff_count_new', axis=1, inplace=True)
    
    if 'count_per_year' not in data.columns:
        # å„ã‚¹ã‚¿ãƒƒãƒ•ã®å¹³å‡å›æ•°ã‚’è¨ˆç®—
        def calc_count_per_year(group):
            years = group['seasonYear'].dropna()
            if len(years) == 0:
                return 0
            year_range = years.max() - years.min() + 1
            return len(group) / max(year_range, 1)
        
        count_per_year_data = filtered_data.groupby('staff_id').apply(calc_count_per_year).reset_index(name='count_per_year')
        staff_aggregated = staff_aggregated.merge(count_per_year_data, on='staff_id', how='left', suffixes=('', '_new'))
        if 'count_per_year_new' in staff_aggregated.columns:
            staff_aggregated['count_per_year'] = staff_aggregated['count_per_year_new']
            staff_aggregated.drop('count_per_year_new', axis=1, inplace=True)
    
    # 3ã¤ã®æŒ‡æ¨™ã®çµ±è¨ˆè¨ˆç®—ç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def calculate_basic_stats_for_staff(series):
        """åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—"""
        series = series.dropna()
        if len(series) == 0:
            return {}
        
        stats = {
            "åˆè¨ˆ": float(series.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": int(len(series)),
            "æœ€å¤§": float(series.max()),
            "æœ€å°": float(series.min()),
            "å¹³å‡": float(series.mean()),
            "ä¸­å¤®å€¤": float(series.median()),
            "1/4åˆ†ä½": float(series.quantile(0.25)),
            "3/4åˆ†ä½": float(series.quantile(0.75))
        }
        
        if len(series) > 1:
            stats["æ¨™æº–åå·®"] = float(series.std())
            stats["åˆ†æ•£"] = float(series.var())
        else:
            stats["æ¨™æº–åå·®"] = 0.0
            stats["åˆ†æ•£"] = 0.0
        
        return stats
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ ã‚¹ã‚¿ãƒƒãƒ•çµ±è¨ˆï¼ˆ{len(staff_aggregated):,}åï¼‰")
    
    # 3ã¤ã®æŒ‡æ¨™ã‚’è¡Œã¨ã—ã¦è¡¨ç¤º
    st.markdown("### ğŸ“Š åŸºç¤çµ±è¨ˆï¼ˆå…¨æœŸé–“ï¼‰")
    
    # å„æŒ‡æ¨™ã®çµ±è¨ˆã‚’è¨ˆç®—
    favorites_stats = calculate_basic_stats_for_staff(staff_aggregated['staff_favorites'])
    count_stats = calculate_basic_stats_for_staff(staff_aggregated['staff_count'])
    avg_count_stats = calculate_basic_stats_for_staff(staff_aggregated['count_per_year'])
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆï¼ˆè¡Œ: æŒ‡æ¨™ã€åˆ—: çµ±è¨ˆé …ç›®ï¼‰
    stats_data = {
        "æŒ‡æ¨™": ["ãŠæ°—ã«å…¥ã‚Šæ•°", "å›æ•°", "å¹³å‡å›æ•°"],
        "åˆè¨ˆ": [favorites_stats.get("åˆè¨ˆ", 0), count_stats.get("åˆè¨ˆ", 0), avg_count_stats.get("åˆè¨ˆ", 0)],
        "ã‚«ã‚¦ãƒ³ãƒˆ": [favorites_stats.get("ã‚«ã‚¦ãƒ³ãƒˆ", 0), count_stats.get("ã‚«ã‚¦ãƒ³ãƒˆ", 0), avg_count_stats.get("ã‚«ã‚¦ãƒ³ãƒˆ", 0)],
        "æœ€å¤§": [favorites_stats.get("æœ€å¤§", 0), count_stats.get("æœ€å¤§", 0), avg_count_stats.get("æœ€å¤§", 0)],
        "æœ€å°": [favorites_stats.get("æœ€å°", 0), count_stats.get("æœ€å°", 0), avg_count_stats.get("æœ€å°", 0)],
        "å¹³å‡": [favorites_stats.get("å¹³å‡", 0), count_stats.get("å¹³å‡", 0), avg_count_stats.get("å¹³å‡", 0)],
        "ä¸­å¤®å€¤": [favorites_stats.get("ä¸­å¤®å€¤", 0), count_stats.get("ä¸­å¤®å€¤", 0), avg_count_stats.get("ä¸­å¤®å€¤", 0)],
        "1/4åˆ†ä½": [favorites_stats.get("1/4åˆ†ä½", 0), count_stats.get("1/4åˆ†ä½", 0), avg_count_stats.get("1/4åˆ†ä½", 0)],
        "3/4åˆ†ä½": [favorites_stats.get("3/4åˆ†ä½", 0), count_stats.get("3/4åˆ†ä½", 0), avg_count_stats.get("3/4åˆ†ä½", 0)],
        "æ¨™æº–åå·®": [favorites_stats.get("æ¨™æº–åå·®", 0), count_stats.get("æ¨™æº–åå·®", 0), avg_count_stats.get("æ¨™æº–åå·®", 0)],
        "åˆ†æ•£": [favorites_stats.get("åˆ†æ•£", 0), count_stats.get("åˆ†æ•£", 0), avg_count_stats.get("åˆ†æ•£", 0)]
    }
    
    stats_df = pd.DataFrame(stats_data)
    st.dataframe(stats_df, use_container_width=True, height=150)
    
    # å…¨æœŸé–“é¸æŠæ™‚ã¯å¹´ä»£åˆ¥çµ±è¨ˆã‚’è¿½åŠ è¡¨ç¤º
    if selected_decade == "å…¨æœŸé–“":
        st.markdown("### ğŸ“… å¹´ä»£åˆ¥åŸºç¤çµ±è¨ˆ")
        
        # å¹´ä»£ã‚’è¿½åŠ 
        def assign_decade(year):
            if pd.isna(year):
                return None
            year = int(year)
            if year < 2000:
                return "1900å¹´ä»£"
            elif year < 2010:
                return "2000å¹´ä»£"
            elif year < 2020:
                return "2010å¹´ä»£"
            else:
                return "2020å¹´ä»£"
        
        filtered_data['decade'] = filtered_data['seasonYear'].apply(assign_decade)
        
        # å¹´ä»£ã”ã¨ã«çµ±è¨ˆã‚’è¨ˆç®—
        decade_stats_list = []
        
        for decade in ["1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]:
            decade_data = filtered_data[filtered_data['decade'] == decade]
            
            if decade_data.empty:
                continue
            
            # å¹´ä»£ã”ã¨ã«ã‚¹ã‚¿ãƒƒãƒ•IDã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            decade_staff_agg = decade_data.groupby('staff_id').agg({
                'staff_favorites': 'first',
                'staff_count': 'first' if 'staff_count' in decade_data.columns else lambda x: len(x),
                'count_per_year': 'first' if 'count_per_year' in decade_data.columns else lambda x: len(x) / max((decade_data.loc[x.index, 'seasonYear'].max() - decade_data.loc[x.index, 'seasonYear'].min() + 1), 1)
            }).reset_index()
            
            # å„æŒ‡æ¨™ã®çµ±è¨ˆã‚’è¨ˆç®—
            fav_stats = calculate_basic_stats_for_staff(decade_staff_agg['staff_favorites'])
            cnt_stats = calculate_basic_stats_for_staff(decade_staff_agg['staff_count'])
            avg_stats = calculate_basic_stats_for_staff(decade_staff_agg['count_per_year'])
            
            # å¹´ä»£åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            for metric, stats in [("ãŠæ°—ã«å…¥ã‚Šæ•°", fav_stats), ("å›æ•°", cnt_stats), ("å¹³å‡å›æ•°", avg_stats)]:
                decade_stats_list.append({
                    "å¹´ä»£": decade,
                    "æŒ‡æ¨™": metric,
                    "åˆè¨ˆ": stats.get("åˆè¨ˆ", 0),
                    "ã‚«ã‚¦ãƒ³ãƒˆ": stats.get("ã‚«ã‚¦ãƒ³ãƒˆ", 0),
                    "æœ€å¤§": stats.get("æœ€å¤§", 0),
                    "æœ€å°": stats.get("æœ€å°", 0),
                    "å¹³å‡": stats.get("å¹³å‡", 0),
                    "ä¸­å¤®å€¤": stats.get("ä¸­å¤®å€¤", 0),
                    "1/4åˆ†ä½": stats.get("1/4åˆ†ä½", 0),
                    "3/4åˆ†ä½": stats.get("3/4åˆ†ä½", 0),
                    "æ¨™æº–åå·®": stats.get("æ¨™æº–åå·®", 0),
                    "åˆ†æ•£": stats.get("åˆ†æ•£", 0)
                })
        
        if decade_stats_list:
            decade_stats_df = pd.DataFrame(decade_stats_list)
            st.dataframe(decade_stats_df, use_container_width=True)
        else:
            st.info("å¹´ä»£åˆ¥çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

def show_manga_genre_statistics_tab(data):
    """ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“š ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ« åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯å…¨ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’ä¸€æ‹¬è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x),
            key="manga_genre_stats_metric"
        )
    
    with col2:
        # å¹´ä»£é¸æŠ
        decades = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decades, key="manga_genre_stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦ç´ ã‹ã‚‰å‹•çš„ç”Ÿæˆï¼‰
        if 'format' in data.columns:
            unique_formats = sorted(data['format'].dropna().unique())
            formats = ["å…¨ã¦"] + list(unique_formats)
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="manga_genre_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    if selected_format != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['format'] == selected_format]
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = create_decade_filter(filtered_data, selected_decade, 'seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—
    if 'genre_name' not in filtered_data.columns:
        st.error("ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    unique_genres = sorted(filtered_data['genre_name'].dropna().unique())
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ")
    st.markdown(f"**é¸æŠå¹´ä»£**: {selected_decade} | **é¸æŠãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: {selected_format} | **ã‚¸ãƒ£ãƒ³ãƒ«æ•°**: {len(unique_genres)}ç¨®é¡")
    
    # å„ã‚¸ãƒ£ãƒ³ãƒ«ã®çµ±è¨ˆã‚’è¨ˆç®—
    genre_stats_list = []
    
    for genre in unique_genres:
        genre_data = filtered_data[filtered_data['genre_name'] == genre].copy()
        
        if genre_data.empty:
            continue
        
        # æŒ‡æ¨™ã®å€¤ã‚’å–å¾—
        metric_values = pd.to_numeric(genre_data[selected_metric], errors='coerce').dropna()
        
        if len(metric_values) == 0:
            continue
        
        # çµ±è¨ˆã‚’è¨ˆç®—
        stats = {
            'ã‚¸ãƒ£ãƒ³ãƒ«': genre,
            'åˆè¨ˆ': metric_values.sum(),
            'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
            'æœ€å¤§': metric_values.max(),
            'æœ€å°': metric_values.min(),
            'å¹³å‡': metric_values.mean(),
            'ä¸­å¤®å€¤': metric_values.median(),
            '1/4åˆ†ä½': metric_values.quantile(0.25),
            '3/4åˆ†ä½': metric_values.quantile(0.75),
            'æ¨™æº–åå·®': metric_values.std(),
            'åˆ†æ•£': metric_values.var()
        }
        genre_stats_list.append(stats)
    
    if not genre_stats_list:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # DataFrameã«å¤‰æ›
    genre_stats_df = pd.DataFrame(genre_stats_list)
    
    # æ•°å€¤å‹ã«å¤‰æ›
    for col in genre_stats_df.columns:
        if col != "ã‚¸ãƒ£ãƒ³ãƒ«":
            genre_stats_df[col] = pd.to_numeric(genre_stats_df[col], errors='ignore')
    
    # 1. å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆè¡¨ï¼ˆå¹³å‡ã§ã‚½ãƒ¼ãƒˆï¼‰
    st.markdown("---")
    st.subheader(f"ğŸ“Š è¡¨1: å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åŸºç¤çµ±è¨ˆ ({selected_metric})")
    sorted_df = genre_stats_df.sort_values('å¹³å‡', ascending=False)
    st.dataframe(sorted_df, width='stretch', height=600)
    
    # 2. å¹´ä»£åˆ¥ãƒ»å¹´æ¬¡åˆ¥ã®è©³ç´°çµ±è¨ˆï¼ˆå…¨æœŸé–“ä»¥å¤–ã®å ´åˆï¼‰
    if selected_decade != "å…¨æœŸé–“":
        st.markdown("---")
        st.subheader(f"ğŸ“Š è¡¨2: {selected_decade} - å„å¹´åº¦ã®ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµ±è¨ˆ")
        
        # å¹´åº¦ã”ã¨ã«ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥çµ±è¨ˆã‚’è¨ˆç®—
        if 'seasonYear' in filtered_data.columns:
            # å¹´åº¦ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆé™é †ï¼‰
            years = sorted(filtered_data['seasonYear'].dropna().unique(), reverse=True)
            
            # å„å¹´åº¦ã®çµ±è¨ˆã‚’è¨ˆç®—
            yearly_genre_stats = []
            
            for year in years:
                year_data = filtered_data[filtered_data['seasonYear'] == year]
                
                for genre in unique_genres:
                    genre_year_data = year_data[year_data['genre_name'] == genre]
                    
                    if genre_year_data.empty:
                        continue
                    
                    metric_values = pd.to_numeric(genre_year_data[selected_metric], errors='coerce').dropna()
                    
                    if len(metric_values) == 0:
                        continue
                    
                    stats = {
                        'å¹´åº¦': int(year),
                        'ã‚¸ãƒ£ãƒ³ãƒ«': genre,
                        'åˆè¨ˆ': metric_values.sum(),
                        'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
                        'æœ€å¤§': metric_values.max(),
                        'æœ€å°': metric_values.min(),
                        'å¹³å‡': metric_values.mean(),
                        'ä¸­å¤®å€¤': metric_values.median(),
                        '1/4åˆ†ä½': metric_values.quantile(0.25),
                        '3/4åˆ†ä½': metric_values.quantile(0.75),
                        'æ¨™æº–åå·®': metric_values.std(),
                        'åˆ†æ•£': metric_values.var()
                    }
                    yearly_genre_stats.append(stats)
            
            if yearly_genre_stats:
                yearly_genre_df = pd.DataFrame(yearly_genre_stats)
                
                # æ•°å€¤å‹ã«å¤‰æ›
                for col in yearly_genre_df.columns:
                    if col not in ["å¹´åº¦", "ã‚¸ãƒ£ãƒ³ãƒ«"]:
                        yearly_genre_df[col] = pd.to_numeric(yearly_genre_df[col], errors='ignore')
                
                st.dataframe(yearly_genre_df, width='stretch', height=600)
                
                # å¹´åº¦åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•ï¼ˆä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®ã¿ï¼‰
                st.markdown("---")
                st.subheader(f"ğŸ“ˆ å¹´åº¦åˆ¥æ¨ç§» - ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«")
                
                # å…¨ä½“ã§å¹³å‡ãŒé«˜ã„ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã‚’å–å¾—
                top_5_genres = sorted_df.head(5)['ã‚¸ãƒ£ãƒ³ãƒ«'].tolist()
                
                # ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                top_5_data = yearly_genre_df[yearly_genre_df['ã‚¸ãƒ£ãƒ³ãƒ«'].isin(top_5_genres)]
                
                if not top_5_data.empty:
                    fig = px.line(
                        top_5_data,
                        x='å¹´åº¦',
                        y='å¹³å‡',
                        color='ã‚¸ãƒ£ãƒ³ãƒ«',
                        markers=True,
                        title=f'{selected_decade} - ä¸Šä½5ã‚¸ãƒ£ãƒ³ãƒ«ã®å¹´åº¦åˆ¥æ¨ç§»',
                        labels={
                            'å¹´åº¦': 'å¹´åº¦',
                            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
                        }
                    )
                    fig.update_layout(height=500, hovermode='x unified')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´åº¦ x ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰
                    st.markdown("---")
                    st.subheader(f"ğŸ”¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— - å¹´åº¦åˆ¥ã‚¸ãƒ£ãƒ³ãƒ«å¹³å‡å€¤")
                    
                    # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                    pivot_data = top_5_data.pivot(index='ã‚¸ãƒ£ãƒ³ãƒ«', columns='å¹´åº¦', values='å¹³å‡')
                    
                    fig_heatmap = px.imshow(
                        pivot_data,
                        labels=dict(x="å¹´åº¦", y="ã‚¸ãƒ£ãƒ³ãƒ«", color=metric_labels.get(selected_metric, selected_metric)),
                        x=pivot_data.columns,
                        y=pivot_data.index,
                        color_continuous_scale='RdYlBu_r',
                        aspect='auto'
                    )
                    fig_heatmap.update_layout(height=400)
                    st.plotly_chart(fig_heatmap, use_container_width=True)
            else:
                st.info("é¸æŠã•ã‚ŒãŸå¹´ä»£ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # 3. ä¸Šä½ãƒ»ä¸‹ä½ã‚¸ãƒ£ãƒ³ãƒ«ã®å¯è¦–åŒ–
    st.markdown("---")
    st.subheader("ğŸ“Š ä¸Šä½ãƒ»ä¸‹ä½ã‚¸ãƒ£ãƒ³ãƒ«æ¯”è¼ƒ")
    
    # ä¸Šä½10ã‚¸ãƒ£ãƒ³ãƒ«
    top_10 = sorted_df.head(10)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"**ä¸Šä½10ã‚¸ãƒ£ãƒ³ãƒ« ({metric_labels.get(selected_metric, selected_metric)})**")
        fig_top = px.bar(
            top_10,
            x='å¹³å‡',
            y='ã‚¸ãƒ£ãƒ³ãƒ«',
            orientation='h',
            text='å¹³å‡',
            color='å¹³å‡',
            color_continuous_scale='Blues'
        )
        fig_top.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_top.update_layout(
            height=400,
            yaxis={'categoryorder': 'total ascending'},
            showlegend=False
        )
        st.plotly_chart(fig_top, use_container_width=True)
    
    with col2:
        # ä¸‹ä½10ã‚¸ãƒ£ãƒ³ãƒ«
        bottom_10 = sorted_df.tail(10)
        st.markdown(f"**ä¸‹ä½10ã‚¸ãƒ£ãƒ³ãƒ« ({metric_labels.get(selected_metric, selected_metric)})**")
        fig_bottom = px.bar(
            bottom_10,
            x='å¹³å‡',
            y='ã‚¸ãƒ£ãƒ³ãƒ«',
            orientation='h',
            text='å¹³å‡',
            color='å¹³å‡',
            color_continuous_scale='Reds'
        )
        fig_bottom.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_bottom.update_layout(
            height=400,
            yaxis={'categoryorder': 'total descending'},
            showlegend=False
        )
        st.plotly_chart(fig_bottom, use_container_width=True)
    
    # 4. å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®å¹³å‡å€¤åˆ†å¸ƒ
    st.markdown("---")
    st.subheader("ğŸ“Š å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®åˆ†å¸ƒ")
    
    fig_dist = px.histogram(
        genre_stats_df,
        x='å¹³å‡',
        nbins=30,
        title=f'{metric_labels.get(selected_metric, selected_metric)}ã®åˆ†å¸ƒ',
        labels={'å¹³å‡': metric_labels.get(selected_metric, selected_metric), 'count': 'ã‚¸ãƒ£ãƒ³ãƒ«æ•°'}
    )
    fig_dist.update_layout(height=400, showlegend=False)
    st.plotly_chart(fig_dist, use_container_width=True)
    
    # 5. ã‚«ã‚¦ãƒ³ãƒˆ vs å¹³å‡ã®æ•£å¸ƒå›³
    st.markdown("---")
    st.subheader("ğŸ“Š ã‚¿ã‚¤ãƒˆãƒ«æ•° vs å¹³å‡å€¤")
    
    fig_scatter = px.scatter(
        genre_stats_df,
        x='ã‚«ã‚¦ãƒ³ãƒˆ',
        y='å¹³å‡',
        text='ã‚¸ãƒ£ãƒ³ãƒ«',
        size='ã‚«ã‚¦ãƒ³ãƒˆ',
        color='å¹³å‡',
        color_continuous_scale='Viridis',
        labels={
            'ã‚«ã‚¦ãƒ³ãƒˆ': 'ã‚¿ã‚¤ãƒˆãƒ«æ•°',
            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
        },
        title=f'ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã‚¿ã‚¤ãƒˆãƒ«æ•°ã¨{metric_labels.get(selected_metric, selected_metric)}ã®é–¢ä¿‚'
    )
    fig_scatter.update_traces(textposition='top center')
    fig_scatter.update_layout(height=500)
    st.plotly_chart(fig_scatter, use_container_width=True)


def show_source_statistics_tab(data):
    """ã‚¢ãƒ‹ãƒ¡åŸä½œåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“– ã‚¢ãƒ‹ãƒ¡åŸä½œ åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯å…¨åŸä½œã‚¿ã‚¤ãƒ—ã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’ä¸€æ‹¬è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x),
            key="source_stats_metric"
        )
    
    with col2:
        # å¹´ä»£é¸æŠ
        decades = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decades, key="source_stats_decade")
    
    with col3:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè¦ç´ ã‹ã‚‰å‹•çš„ç”Ÿæˆï¼‰
        if 'format' in data.columns:
            unique_formats = sorted(data['format'].dropna().unique())
            formats = ["å…¨ã¦"] + list(unique_formats)
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="source_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    if selected_format != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['format'] == selected_format]
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = create_decade_filter(filtered_data, selected_decade, 'seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å…¨åŸä½œã‚¿ã‚¤ãƒ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—
    if 'source' not in filtered_data.columns:
        st.error("åŸä½œãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    unique_sources = sorted(filtered_data['source'].dropna().unique())
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ")
    st.markdown(f"**é¸æŠå¹´ä»£**: {selected_decade} | **é¸æŠãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: {selected_format} | **åŸä½œã‚¿ã‚¤ãƒ—æ•°**: {len(unique_sources)}ç¨®é¡")
    
    # å„åŸä½œã‚¿ã‚¤ãƒ—ã®çµ±è¨ˆã‚’è¨ˆç®—
    source_stats_list = []
    
    for source in unique_sources:
        source_data = filtered_data[filtered_data['source'] == source].copy()
        
        if source_data.empty:
            continue
        
        # æŒ‡æ¨™ã®å€¤ã‚’å–å¾—
        metric_values = pd.to_numeric(source_data[selected_metric], errors='coerce').dropna()
        
        if len(metric_values) == 0:
            continue
        
        # çµ±è¨ˆã‚’è¨ˆç®—
        stats = {
            'åŸä½œ': source,
            'åˆè¨ˆ': metric_values.sum(),
            'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
            'æœ€å¤§': metric_values.max(),
            'æœ€å°': metric_values.min(),
            'å¹³å‡': metric_values.mean(),
            'ä¸­å¤®å€¤': metric_values.median(),
            '1/4åˆ†ä½': metric_values.quantile(0.25),
            '3/4åˆ†ä½': metric_values.quantile(0.75),
            'æ¨™æº–åå·®': metric_values.std(),
            'åˆ†æ•£': metric_values.var()
        }
        source_stats_list.append(stats)
    
    if not source_stats_list:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # DataFrameã«å¤‰æ›
    source_stats_df = pd.DataFrame(source_stats_list)
    
    # æ•°å€¤å‹ã«å¤‰æ›
    for col in source_stats_df.columns:
        if col != "åŸä½œ":
            source_stats_df[col] = pd.to_numeric(source_stats_df[col], errors='ignore')
    
    # 1. å…¨åŸä½œã‚¿ã‚¤ãƒ—ã®åŸºç¤çµ±è¨ˆè¡¨ï¼ˆå¹³å‡ã§ã‚½ãƒ¼ãƒˆï¼‰
    st.markdown("---")
    st.subheader(f"ğŸ“Š è¡¨1: å…¨åŸä½œã‚¿ã‚¤ãƒ—ã®åŸºç¤çµ±è¨ˆ ({selected_metric})")
    sorted_df = source_stats_df.sort_values('å¹³å‡', ascending=False)
    st.dataframe(sorted_df, width='stretch', height=400)
    
    # 2. å¹´ä»£åˆ¥ãƒ»å¹´æ¬¡åˆ¥ã®è©³ç´°çµ±è¨ˆï¼ˆå…¨æœŸé–“ä»¥å¤–ã®å ´åˆï¼‰
    if selected_decade != "å…¨æœŸé–“":
        st.markdown("---")
        st.subheader(f"ğŸ“Š è¡¨2: {selected_decade} - å„å¹´åº¦ã®åŸä½œåˆ¥çµ±è¨ˆ")
        
        # å¹´åº¦ã”ã¨ã«åŸä½œåˆ¥çµ±è¨ˆã‚’è¨ˆç®—
        if 'seasonYear' in filtered_data.columns:
            # å¹´åº¦ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆé™é †ï¼‰
            years = sorted(filtered_data['seasonYear'].dropna().unique(), reverse=True)
            
            # å„å¹´åº¦ã®çµ±è¨ˆã‚’è¨ˆç®—
            yearly_source_stats = []
            
            for year in years:
                year_data = filtered_data[filtered_data['seasonYear'] == year]
                
                for source in unique_sources:
                    source_year_data = year_data[year_data['source'] == source]
                    
                    if source_year_data.empty:
                        continue
                    
                    metric_values = pd.to_numeric(source_year_data[selected_metric], errors='coerce').dropna()
                    
                    if len(metric_values) == 0:
                        continue
                    
                    stats = {
                        'å¹´åº¦': int(year),
                        'åŸä½œ': source,
                        'åˆè¨ˆ': metric_values.sum(),
                        'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
                        'æœ€å¤§': metric_values.max(),
                        'æœ€å°': metric_values.min(),
                        'å¹³å‡': metric_values.mean(),
                        'ä¸­å¤®å€¤': metric_values.median(),
                        '1/4åˆ†ä½': metric_values.quantile(0.25),
                        '3/4åˆ†ä½': metric_values.quantile(0.75),
                        'æ¨™æº–åå·®': metric_values.std(),
                        'åˆ†æ•£': metric_values.var()
                    }
                    yearly_source_stats.append(stats)
            
            if yearly_source_stats:
                yearly_source_df = pd.DataFrame(yearly_source_stats)
                
                # æ•°å€¤å‹ã«å¤‰æ›
                for col in yearly_source_df.columns:
                    if col not in ["å¹´åº¦", "åŸä½œ"]:
                        yearly_source_df[col] = pd.to_numeric(yearly_source_df[col], errors='ignore')
                
                st.dataframe(yearly_source_df, width='stretch', height=600)
                
                # å¹´åº¦åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•ï¼ˆå…¨åŸä½œã‚¿ã‚¤ãƒ—ï¼‰
                st.markdown("---")
                st.subheader(f"ğŸ“ˆ å¹´åº¦åˆ¥æ¨ç§» - å…¨åŸä½œã‚¿ã‚¤ãƒ—")
                
                if not yearly_source_df.empty:
                    fig = px.line(
                        yearly_source_df,
                        x='å¹´åº¦',
                        y='å¹³å‡',
                        color='åŸä½œ',
                        markers=True,
                        title=f'{selected_decade} - åŸä½œåˆ¥ã®å¹´åº¦åˆ¥æ¨ç§»',
                        labels={
                            'å¹´åº¦': 'å¹´åº¦',
                            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
                        }
                    )
                    fig.update_layout(height=500, hovermode='x unified')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´åº¦ x åŸä½œï¼‰
                    st.markdown("---")
                    st.subheader(f"ğŸ”¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— - å¹´åº¦åˆ¥åŸä½œå¹³å‡å€¤")
                    
                    # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                    pivot_data = yearly_source_df.pivot(index='åŸä½œ', columns='å¹´åº¦', values='å¹³å‡')
                    
                    fig_heatmap = px.imshow(
                        pivot_data,
                        labels=dict(x="å¹´åº¦", y="åŸä½œ", color=metric_labels.get(selected_metric, selected_metric)),
                        x=pivot_data.columns,
                        y=pivot_data.index,
                        color_continuous_scale='RdYlBu_r',
                        aspect='auto'
                    )
                    fig_heatmap.update_layout(height=400)
                    st.plotly_chart(fig_heatmap, use_container_width=True)
            else:
                st.info("é¸æŠã•ã‚ŒãŸå¹´ä»£ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # 3. å…¨æœŸé–“é¸æŠæ™‚ã®å¹´ä»£åˆ¥çµ±è¨ˆ
    if selected_decade == "å…¨æœŸé–“":
        st.markdown("---")
        st.subheader("ğŸ“Š è¡¨2: å¹´ä»£åˆ¥ã®åŸä½œåˆ¥çµ±è¨ˆ")
        
        # å¹´ä»£å®šç¾©
        decade_ranges = {
            "1900å¹´ä»£": (1900, 1999),
            "2000å¹´ä»£": (2000, 2009),
            "2010å¹´ä»£": (2010, 2019),
            "2020å¹´ä»£": (2020, 2029)
        }
        
        decade_source_stats = []
        
        for decade_name, (start_year, end_year) in decade_ranges.items():
            decade_data = filtered_data[
                (filtered_data['seasonYear'] >= start_year) & 
                (filtered_data['seasonYear'] <= end_year)
            ]
            
            if decade_data.empty:
                continue
            
            for source in unique_sources:
                source_decade_data = decade_data[decade_data['source'] == source]
                
                if source_decade_data.empty:
                    continue
                
                metric_values = pd.to_numeric(source_decade_data[selected_metric], errors='coerce').dropna()
                
                if len(metric_values) == 0:
                    continue
                
                stats = {
                    'å¹´ä»£': decade_name,
                    'åŸä½œ': source,
                    'åˆè¨ˆ': metric_values.sum(),
                    'ã‚«ã‚¦ãƒ³ãƒˆ': len(metric_values),
                    'æœ€å¤§': metric_values.max(),
                    'æœ€å°': metric_values.min(),
                    'å¹³å‡': metric_values.mean(),
                    'ä¸­å¤®å€¤': metric_values.median(),
                    '1/4åˆ†ä½': metric_values.quantile(0.25),
                    '3/4åˆ†ä½': metric_values.quantile(0.75),
                    'æ¨™æº–åå·®': metric_values.std(),
                    'åˆ†æ•£': metric_values.var()
                }
                decade_source_stats.append(stats)
        
        if decade_source_stats:
            decade_source_df = pd.DataFrame(decade_source_stats)
            
            # æ•°å€¤å‹ã«å¤‰æ›
            for col in decade_source_df.columns:
                if col not in ["å¹´ä»£", "åŸä½œ"]:
                    decade_source_df[col] = pd.to_numeric(decade_source_df[col], errors='ignore')
            
            st.dataframe(decade_source_df, width='stretch', height=600)
            
            # å¹´ä»£åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•
            st.markdown("---")
            st.subheader("ğŸ“ˆ å¹´ä»£åˆ¥æ¨ç§» - å…¨åŸä½œã‚¿ã‚¤ãƒ—")
            
            fig_decade = px.line(
                decade_source_df,
                x='å¹´ä»£',
                y='å¹³å‡',
                color='åŸä½œ',
                markers=True,
                title=f'å¹´ä»£åˆ¥åŸä½œã‚¿ã‚¤ãƒ—åˆ¥æ¨ç§»',
                labels={
                    'å¹´ä»£': 'å¹´ä»£',
                    'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
                }
            )
            fig_decade.update_layout(height=500, hovermode='x unified')
            st.plotly_chart(fig_decade, use_container_width=True)
        else:
            st.info("å¹´ä»£åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # 4. åŸä½œã‚¿ã‚¤ãƒ—æ¯”è¼ƒã®æ¨ªæ£’ã‚°ãƒ©ãƒ•
    st.markdown("---")
    st.subheader("ğŸ“Š åŸä½œã‚¿ã‚¤ãƒ—åˆ¥æ¯”è¼ƒ")
    
    fig_bar = px.bar(
        sorted_df,
        x='å¹³å‡',
        y='åŸä½œ',
        orientation='h',
        text='å¹³å‡',
        color='å¹³å‡',
        color_continuous_scale='Viridis',
        title=f'åŸä½œã‚¿ã‚¤ãƒ—åˆ¥ {metric_labels.get(selected_metric, selected_metric)} å¹³å‡å€¤'
    )
    fig_bar.update_traces(texttemplate='%{text:.2f}', textposition='outside')
    fig_bar.update_layout(
        height=400,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False
    )
    st.plotly_chart(fig_bar, use_container_width=True)
    
    # 5. ã‚«ã‚¦ãƒ³ãƒˆ vs å¹³å‡ã®æ•£å¸ƒå›³
    st.markdown("---")
    st.subheader("ğŸ“Š ã‚¿ã‚¤ãƒˆãƒ«æ•° vs å¹³å‡å€¤")
    
    fig_scatter = px.scatter(
        source_stats_df,
        x='ã‚«ã‚¦ãƒ³ãƒˆ',
        y='å¹³å‡',
        text='åŸä½œ',
        size='ã‚«ã‚¦ãƒ³ãƒˆ',
        color='å¹³å‡',
        color_continuous_scale='Viridis',
        labels={
            'ã‚«ã‚¦ãƒ³ãƒˆ': 'ã‚¿ã‚¤ãƒˆãƒ«æ•°',
            'å¹³å‡': metric_labels.get(selected_metric, selected_metric)
        },
        title=f'åŸä½œåˆ¥ã‚¿ã‚¤ãƒˆãƒ«æ•°ã¨{metric_labels.get(selected_metric, selected_metric)}ã®é–¢ä¿‚'
    )
    fig_scatter.update_traces(textposition='top center')
    fig_scatter.update_layout(height=500)
    st.plotly_chart(fig_scatter, use_container_width=True)


def show_studio_statistics_tab(data):
    """ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¸ã‚ªåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º - ã‚¹ã‚¿ã‚¸ã‚ªã®å›æ•°ã®åŸºç¤çµ±è¨ˆ"""
    st.header("ğŸ¬ ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¸ã‚ª åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯ã‚¹ã‚¿ã‚¸ã‚ªã®å›æ•°ï¼ˆä½œå“æ•°ï¼‰ã®åŸºç¤çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # å¹´ä»£é¸æŠ
        decades = ["å…¨æœŸé–“", "1900å¹´ä»£", "2000å¹´ä»£", "2010å¹´ä»£", "2020å¹´ä»£"]
        selected_decade = st.selectbox("å¹´ä»£", decades, key="studio_stats_decade")
    
    with col2:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            unique_formats = sorted(data['format'].dropna().unique())
            formats = ["å…¨ã¦"] + list(unique_formats)
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="studio_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            unique_sources = sorted(data['source'].dropna().unique())
            sources = ["å…¨ã¦"] + list(unique_sources)
            selected_source = st.selectbox("åŸä½œ", sources, key="studio_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    with col4:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆè¤‡æ•°ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æŒã¤ä½œå“ãŒã‚ã‚‹ãŸã‚ã€å˜ä¸€ã‚¸ãƒ£ãƒ³ãƒ«ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        if 'genres' in data.columns:
            # å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æŠ½å‡º
            all_genres = set()
            for genres_str in data['genres'].dropna():
                if genres_str != 'Unknown':
                    all_genres.update([g.strip() for g in genres_str.split(',')])
            unique_genres = sorted(list(all_genres))
            genres = ["å…¨ã¦"] + unique_genres
            selected_genre = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres, key="studio_stats_genre")
        else:
            selected_genre = "å…¨ã¦"
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = data.copy()
    
    if selected_format != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['format'] == selected_format]
    
    if selected_source != "å…¨ã¦":
        filtered_data = filtered_data[filtered_data['source'] == selected_source]
    
    if selected_genre != "å…¨ã¦":
        # ã‚¸ãƒ£ãƒ³ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹ä½œå“ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        filtered_data = filtered_data[filtered_data['genres'].str.contains(selected_genre, na=False)]
    
    # å¹´ä»£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = create_decade_filter(filtered_data, selected_decade, 'seasonYear')
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®ä½œå“æ•°ã‚’é›†è¨ˆ
    if 'studios_name' not in filtered_data.columns:
        st.error("ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # å„ã‚¹ã‚¿ã‚¸ã‚ªã®ä½œå“æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    studio_counts = filtered_data.groupby('studios_name').size().reset_index(name='ä½œå“æ•°')
    
    # åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—
    def calculate_basic_stats(series):
        """åŸºç¤çµ±è¨ˆã‚’è¨ˆç®—"""
        series = series.dropna()
        if len(series) == 0:
            return {}
        
        stats = {
            "åˆè¨ˆ": float(series.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": int(len(series)),
            "æœ€å¤§": float(series.max()),
            "æœ€å°": float(series.min()),
            "å¹³å‡": float(series.mean()),
            "ä¸­å¤®å€¤": float(series.median()),
            "1/4åˆ†ä½": float(series.quantile(0.25)),
            "3/4åˆ†ä½": float(series.quantile(0.75))
        }
        
        if len(series) > 1:
            stats["æ¨™æº–åå·®"] = float(series.std())
            stats["åˆ†æ•£"] = float(series.var())
        else:
            stats["æ¨™æº–åå·®"] = 0.0
            stats["åˆ†æ•£"] = 0.0
        
        return stats
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ ã‚¹ã‚¿ã‚¸ã‚ªçµ±è¨ˆï¼ˆ{len(studio_counts):,}ç¤¾ï¼‰")
    
    # åŸºç¤çµ±è¨ˆè¡¨
    st.markdown("### ğŸ“Š ã‚¹ã‚¿ã‚¸ã‚ªã®å›æ•°ï¼ˆä½œå“æ•°ï¼‰ã®åŸºç¤çµ±è¨ˆ")
    count_stats = calculate_basic_stats(studio_counts['ä½œå“æ•°'])
    if count_stats:
        count_df = pd.DataFrame(
            [(key, value) for key, value in count_stats.items()],
            columns=["çµ±è¨ˆé …ç›®", "ä½œå“æ•°"]
        )
        st.dataframe(count_df, use_container_width=True, height=400)
    else:
        st.warning("ä½œå“æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")


def show_scatter_tab(data, genre):
    """ç›¸é–¢åˆ†æã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header(f"ğŸ” {genre} ç›¸é–¢åˆ†æ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸ2ã¤ã®æŒ‡æ¨™é–“ã®ç›¸é–¢é–¢ä¿‚ã‚’åˆ†æã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã‚«ãƒ©ãƒ ã‚’ã‚¯ã‚¨ãƒªã«è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å†å–å¾—
    try:
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
            conn = sqlite3.connect(str(db_path))
            query = """
                SELECT 
                    a.anilist_id, a.title_romaji, a.title_native, a.format, 
                    a.season, a.seasonYear, a.favorites, a.meanScore, 
                    a.popularity, a.source, a.episode
                FROM anime a
                WHERE a.title_romaji IS NOT NULL
            """
            extended_data = pd.read_sql_query(query, conn)
            conn.close()
        else:
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
            extended_data = data.copy()
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        else:
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        extended_data = data.copy()
    
    # é¸æŠè‚¢ã®å®šç¾©
    categorical_options = {
        "format": "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
        "season": "ã‚·ãƒ¼ã‚ºãƒ³", 
        "seasonYear": "å¹´åº¦",
        "source": "ã‚½ãƒ¼ã‚¹"
    }
    
    numerical_options = {
        "episode": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°",
        "favorites": "ãŠæ°—ã«å…¥ã‚Š",
        "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
        "popularity": "äººæ°—åº¦"
    }
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        try:
            available_genres = get_genres_data(db_path)
            if available_genres:
                categorical_options["genre"] = "ã‚¸ãƒ£ãƒ³ãƒ«"
        except:
            pass
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'seasonYear' in extended_data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(extended_data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="corr_year")
        elif genre == "æ¼«ç”»" and 'seasonYear' in extended_data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(extended_data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="corr_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠï¼ˆã‚¢ãƒ‹ãƒ¡ã®ã¿ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'season' in extended_data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(extended_data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="corr_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in extended_data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(extended_data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="corr_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in extended_data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(extended_data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="corr_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            try:
                available_genres = get_genres_data(db_path)
                genres_options = ["å…¨ã¦"] + available_genres
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="corr_genre_filter")
            except:
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="corr_genre_filter")
        else:
            # ãƒãƒ³ã‚¬ã®å ´åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®š
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="corr_genre_filter")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        if selected_year != "å…¨ã¦":
            try:
                filters['seasonYear'] = float(selected_year)
            except ValueError:
                pass
        if selected_season != "å…¨ã¦":
            filters['season'] = selected_season
    elif genre == "æ¼«ç”»":
        if selected_year != "å…¨ã¦":
            try:
                filters['seasonYear'] = float(selected_year)
            except ValueError:
                pass
    
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = filter_data(extended_data, filters, db_path if db_path.exists() else None)
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’è¡¨ç¤º
    filtered_count = len(filtered_data)
    st.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {filtered_count:,}ä»¶")
    
    # ç›¸é–¢åˆ†æè¨­å®š
    st.subheader("ğŸ”§ ç›¸é–¢åˆ†æè¨­å®š")
    
    # åˆ†æãƒ¢ãƒ¼ãƒ‰é¸æŠ
    analysis_mode = st.radio(
        "åˆ†æãƒ¢ãƒ¼ãƒ‰",
        ["å˜ä¸€ç›¸é–¢åˆ†æ", "è¤‡æ•°ç›¸é–¢åˆ†æ"],
        key="analysis_mode",
        horizontal=True
    )
    
    if analysis_mode == "å˜ä¸€ç›¸é–¢åˆ†æ":
        # å˜ä¸€ç›¸é–¢åˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            # é¸æŠè‚¢1ï¼ˆæ•°å€¤ã®ã¿ï¼‰
            selected_var1 = st.selectbox(
                "é¸æŠè‚¢1ï¼ˆæ•°å€¤é …ç›®ï¼‰",
                list(numerical_options.keys()),
                format_func=lambda x: numerical_options.get(x, x),
                key="single_var1"
            )
        
        with col2:
            # é¸æŠè‚¢2ï¼ˆæ•°å€¤ã®ã¿ï¼‰
            selected_var2 = st.selectbox(
                "é¸æŠè‚¢2ï¼ˆæ•°å€¤é …ç›®ï¼‰",
                list(numerical_options.keys()),
                format_func=lambda x: numerical_options.get(x, x),
                key="single_var2"
            )
        
        # å˜ä¸€ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
        if selected_var1 != selected_var2:
            show_numerical_correlation(filtered_data, selected_var1, selected_var2, numerical_options, numerical_options)
        else:
            st.warning("åŒã˜é …ç›®åŒå£«ã®ç›¸é–¢ã¯åˆ†æã§ãã¾ã›ã‚“ã€‚ç•°ãªã‚‹é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    
    else:
        # è¤‡æ•°ç›¸é–¢åˆ†æ
        st.markdown("**è¤‡æ•°é …ç›®é–“ã®ç›¸é–¢ä¿‚æ•°ã‚’ä¸€åº¦ã«è¡¨ç¤ºã—ã¾ã™**")
        
        # åˆ†æå¯¾è±¡é …ç›®ã®é¸æŠ
        selected_vars = st.multiselect(
            "åˆ†æã™ã‚‹é …ç›®ã‚’é¸æŠï¼ˆ2ã¤ä»¥ä¸Šï¼‰",
            list(numerical_options.keys()),
            default=list(numerical_options.keys())[:3],  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®3é …ç›®ã‚’é¸æŠ
            format_func=lambda x: numerical_options.get(x, x),
            key="multi_vars"
        )
        
        if len(selected_vars) < 2:
            st.warning("2ã¤ä»¥ä¸Šã®é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            # è¤‡æ•°ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
            show_multiple_correlation(filtered_data, selected_vars, numerical_options)

def show_numerical_correlation(data, var1, var2, options1, options2):
    """æ•°å€¤å¤‰æ•°åŒå£«ã®ç›¸é–¢åˆ†æ"""
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    clean_data = data[[var1, var2, 'title_romaji']].dropna()
    
    if len(clean_data) < 2:
        st.error("ç›¸é–¢åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
    correlation = clean_data[var1].corr(clean_data[var2])
    
    # æ•£å¸ƒå›³ã®ä½œæˆï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    fig = px.scatter(
        clean_data,
        x=var1,
        y=var2,
        hover_name='title_romaji',
        title=f"{options1.get(var1)} vs {options2.get(var2)} ã®ç›¸é–¢åˆ†æï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
        labels={
            var1: options1.get(var1),
            var2: options2.get(var2)
        },
        log_x=True,
        log_y=True
    )
    
    # å›å¸°ç·šã®è¿½åŠ ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    try:
        fig.add_traces(
            px.scatter(clean_data, x=var1, y=var2, trendline="ols", log_x=True, log_y=True).data[1:]
        )
    except:
        # å›å¸°ç·šã®è¿½åŠ ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        pass
    
    fig.update_layout(height=500)
    st.plotly_chart(fig, width='stretch')
    
    # ç›¸é–¢ä¿‚æ•°ã‚’æ•£å¸ƒå›³ã®ä¸‹ã«è¡¨ç¤º
    st.subheader("ğŸ“Š ç›¸é–¢ä¿‚æ•°")
    
    # ç›¸é–¢ä¿‚æ•°
    st.metric("ç›¸é–¢ä¿‚æ•°", f"{correlation:.4f}")
    
    # ç›¸é–¢ã®å¼·ã•åˆ¤å®š
    abs_corr = abs(correlation)
    if abs_corr >= 0.8:
        strength = "éå¸¸ã«å¼·ã„"
        color = "ğŸ”´"
    elif abs_corr >= 0.6:
        strength = "å¼·ã„"
        color = "ğŸŸ "
    elif abs_corr >= 0.4:
        strength = "ä¸­ç¨‹åº¦"
        color = "ğŸŸ¡"
    elif abs_corr >= 0.2:
        strength = "å¼±ã„"
        color = "ğŸŸ¢"
    else:
        strength = "éå¸¸ã«å¼±ã„"
        color = "âšª"
    
    st.metric("ç›¸é–¢ã®å¼·ã•", f"{color} {strength}")
    
    # ç›¸é–¢ã®æ–¹å‘
    direction = "æ­£ã®ç›¸é–¢" if correlation > 0 else "è² ã®ç›¸é–¢"
    st.metric("ç›¸é–¢ã®æ–¹å‘", direction)
    
    # ãƒ‡ãƒ¼ã‚¿æ•°
    st.metric("åˆ†æãƒ‡ãƒ¼ã‚¿æ•°", f"{len(clean_data):,}ä»¶")

def show_multiple_correlation(data, selected_vars, numerical_options):
    """è¤‡æ•°å¤‰æ•°é–“ã®ç›¸é–¢åˆ†æ"""
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    analysis_columns = selected_vars + ['title_romaji']
    clean_data = data[analysis_columns].dropna()
    
    if len(clean_data) < 2:
        st.error("ç›¸é–¢åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
    corr_matrix = clean_data[selected_vars].corr()
    
    # ç›¸é–¢è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    st.subheader("ğŸ“Š ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    
    fig_heatmap = px.imshow(
        corr_matrix,
        labels=dict(x="é …ç›®", y="é …ç›®", color="ç›¸é–¢ä¿‚æ•°"),
        x=[numerical_options.get(var, var) for var in selected_vars],
        y=[numerical_options.get(var, var) for var in selected_vars],
        color_continuous_scale="RdBu",
        aspect="auto",
        title="ç›¸é–¢ä¿‚æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
    )
    
    # ç›¸é–¢ä¿‚æ•°ã‚’å„ã‚»ãƒ«ã«è¡¨ç¤º
    for i in range(len(selected_vars)):
        for j in range(len(selected_vars)):
            fig_heatmap.add_annotation(
                x=j, y=i,
                text=f"{corr_matrix.iloc[i, j]:.3f}",
                showarrow=False,
                font=dict(color="white" if abs(corr_matrix.iloc[i, j]) > 0.5 else "black")
            )
    
    fig_heatmap.update_layout(height=500)
    st.plotly_chart(fig_heatmap, width='stretch')
    
    # å€‹åˆ¥ã®æ•£å¸ƒå›³ï¼ˆå¼·ã„ç›¸é–¢ã®ãƒšã‚¢ã®ã¿ï¼‰
    st.subheader("ğŸ” ä¸»è¦ãªç›¸é–¢é–¢ä¿‚ã®æ•£å¸ƒå›³")
    
    # å¼·ã„ç›¸é–¢ï¼ˆçµ¶å¯¾å€¤0.3ä»¥ä¸Šï¼‰ã®ãƒšã‚¢ã‚’æŠ½å‡º
    strong_correlations = []
    for i in range(len(selected_vars)):
        for j in range(i+1, len(selected_vars)):
            corr_value = corr_matrix.iloc[i, j]
            if abs(corr_value) >= 0.3:
                strong_correlations.append({
                    'var1': selected_vars[i],
                    'var2': selected_vars[j],
                    'correlation': corr_value,
                    'abs_correlation': abs(corr_value)
                })
    
    # ç›¸é–¢ã®å¼·ã•ã§ã‚½ãƒ¼ãƒˆ
    strong_correlations.sort(key=lambda x: x['abs_correlation'], reverse=True)
    
    if not strong_correlations:
        st.info("ç›¸é–¢ä¿‚æ•°ã®çµ¶å¯¾å€¤ãŒ0.3ä»¥ä¸Šã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("ã™ã¹ã¦ã®ãƒšã‚¢ã®ç›¸é–¢ä¿‚æ•°ã¯ä¸Šã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§ç¢ºèªã§ãã¾ã™ã€‚")
    else:
        # ä¸Šä½ã®ç›¸é–¢ãƒšã‚¢ã®æ•£å¸ƒå›³ã‚’è¡¨ç¤ºï¼ˆæœ€å¤§3ãƒšã‚¢ï¼‰
        for idx, corr_info in enumerate(strong_correlations[:3]):
            var1, var2 = corr_info['var1'], corr_info['var2']
            correlation = corr_info['correlation']
            
            st.write(f"**{numerical_options.get(var1)} vs {numerical_options.get(var2)}**")
            
            # æ•£å¸ƒå›³ã®ä½œæˆï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            pair_data = clean_data[[var1, var2, 'title_romaji']].dropna()
            
            if len(pair_data) >= 2:
                fig = px.scatter(
                    pair_data,
                    x=var1,
                    y=var2,
                    hover_name='title_romaji',
                    labels={
                        var1: numerical_options.get(var1),
                        var2: numerical_options.get(var2)
                    },
                    log_x=True,
                    log_y=True
                )
                
                # å›å¸°ç·šã®è¿½åŠ ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                try:
                    fig.add_traces(
                        px.scatter(pair_data, x=var1, y=var2, trendline="ols", log_x=True, log_y=True).data[1:]
                    )
                except:
                    # å›å¸°ç·šã®è¿½åŠ ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, width='stretch')
                
                # ç›¸é–¢ä¿‚æ•°ã‚’è¡¨ç¤º
                st.metric("ç›¸é–¢ä¿‚æ•°", f"{correlation:.4f}")
                
                # ç›¸é–¢ã®å¼·ã•åˆ¤å®š
                abs_corr = abs(correlation)
                if abs_corr >= 0.8:
                    strength = "éå¸¸ã«å¼·ã„"
                    color = "ğŸ”´"
                elif abs_corr >= 0.6:
                    strength = "å¼·ã„"
                    color = "ğŸŸ "
                elif abs_corr >= 0.4:
                    strength = "ä¸­ç¨‹åº¦"
                    color = "ğŸŸ¡"
                elif abs_corr >= 0.2:
                    strength = "å¼±ã„"
                    color = "ğŸŸ¢"
                else:
                    strength = "éå¸¸ã«å¼±ã„"
                    color = "âšª"
                
                st.metric("ç›¸é–¢ã®å¼·ã•", f"{color} {strength}")
                
                # ç›¸é–¢ã®æ–¹å‘ã¨ ãƒ‡ãƒ¼ã‚¿æ•°
                direction = "æ­£ã®ç›¸é–¢" if correlation > 0 else "è² ã®ç›¸é–¢"
                st.metric("ç›¸é–¢ã®æ–¹å‘", direction)
                
                st.metric("åˆ†æãƒ‡ãƒ¼ã‚¿æ•°", f"{len(pair_data):,}ä»¶")
                
                if idx < len(strong_correlations[:3]) - 1:
                    st.markdown("---")
    
    # å…¨ãƒšã‚¢ã®ç›¸é–¢ä¿‚æ•°ä¸€è¦§è¡¨ç¤º
    st.subheader("ğŸ“‹ å…¨ãƒšã‚¢ç›¸é–¢ä¿‚æ•°ä¸€è¦§")
    correlation_list = []
    for i in range(len(selected_vars)):
        for j in range(i+1, len(selected_vars)):
            correlation_list.append({
                'é …ç›®1': numerical_options.get(selected_vars[i]),
                'é …ç›®2': numerical_options.get(selected_vars[j]),
                'ç›¸é–¢ä¿‚æ•°': f"{corr_matrix.iloc[i, j]:.4f}"
            })
    
    correlation_df = pd.DataFrame(correlation_list)
    correlation_df = correlation_df.sort_values('ç›¸é–¢ä¿‚æ•°', key=lambda x: x.astype(float).abs(), ascending=False)
    st.dataframe(correlation_df, width='stretch', height=300)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ“Š AniList ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    st.sidebar.title("ğŸ“‹ ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    
    # çµ±åˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆã‚¢ãƒ‹ãƒ¡ã¨ãƒãƒ³ã‚¬ã‚’1ã¤ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã«ï¼‰
    menu_options = [
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¿ã‚¤ãƒˆãƒ«",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚­ãƒ£ãƒ©",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - å£°å„ª",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¹ã‚¿ãƒƒãƒ•",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¹ã‚¿ã‚¸ã‚ª",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - åŸä½œ",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¸ãƒ£ãƒ³ãƒ«",
        "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°",
        "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¿ã‚¤ãƒˆãƒ«",
        "ğŸ“š ãƒãƒ³ã‚¬ - ã‚­ãƒ£ãƒ©",
        "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¹ã‚¿ãƒƒãƒ•",
        "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¸ãƒ£ãƒ³ãƒ«",
        "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"
    ]
    
    selected_menu = st.sidebar.radio(
        "åˆ†æé …ç›®ã‚’é¸æŠ:",
        menu_options,
        key="main_menu"
    )
    
    # é¸æŠã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
    if selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¿ã‚¤ãƒˆãƒ«":
        # æ—¢å­˜ã®ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«åˆ†æï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€åŸºç¤çµ±è¨ˆã€ç›¸é–¢åˆ†æï¼‰
        data = load_anime_data()
        if data is None:
            st.error("ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["åŸºç¤çµ±è¨ˆ", "ç›¸é–¢åˆ†æ"])
        
        with tab1:
            show_statistics_tab(data, "ã‚¢ãƒ‹ãƒ¡")
        
        with tab2:
            show_scatter_tab(data, "ã‚¢ãƒ‹ãƒ¡")
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚­ãƒ£ãƒ©":
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ†æ
        data = load_character_data()
        if data is None:
            st.error("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_character_statistics_tab(data)
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - å£°å„ª":
        # å£°å„ªåˆ†æ
        data = load_voiceactor_data()
        if data is None:
            st.error("å£°å„ªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_voiceactor_statistics_tab(data)
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¹ã‚¿ãƒƒãƒ•":
        # ã‚¹ã‚¿ãƒƒãƒ•åˆ†æ
        data = load_staff_data()
        if data is None:
            st.error("ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_staff_statistics_tab(data)
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¹ã‚¿ã‚¸ã‚ª":
        # ã‚¹ã‚¿ã‚¸ã‚ªåˆ†æ
        data = load_studio_data()
        if data is None:
            st.error("ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_studio_statistics_tab(data)
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - ã‚¸ãƒ£ãƒ³ãƒ«":
        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ†æ
        data = load_genre_data()
        if data is None:
            st.error("ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_genre_statistics_tab(data)
    
    elif selected_menu == "ğŸ¬ ã‚¢ãƒ‹ãƒ¡ - åŸä½œ":
        # åŸä½œåˆ†æ
        data = load_source_data()
        if data is None:
            st.error("åŸä½œãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_source_statistics_tab(data)
    
    elif selected_menu == "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¿ã‚¤ãƒˆãƒ«":
        # ãƒãƒ³ã‚¬ã‚¿ã‚¤ãƒˆãƒ«åˆ†æ
        data = load_manga_data()
        if data is None:
            st.error("ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["åŸºç¤çµ±è¨ˆ", "ç›¸é–¢åˆ†æ"])
        
        with tab1:
            show_statistics_tab(data, "æ¼«ç”»")
        
        with tab2:
            show_scatter_tab(data, "æ¼«ç”»")
    
    elif selected_menu == "ğŸ“š ãƒãƒ³ã‚¬ - ã‚­ãƒ£ãƒ©":
        # ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ†æ
        data = load_manga_character_data()
        if data is None:
            st.error("ãƒãƒ³ã‚¬ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_manga_character_statistics_tab(data)
    
    elif selected_menu == "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¹ã‚¿ãƒƒãƒ•":
        # ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ•åˆ†æ
        data = load_manga_staff_data()
        if data is None:
            st.error("ãƒãƒ³ã‚¬ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_manga_staff_statistics_tab(data)
    
    elif selected_menu == "ğŸ“š ãƒãƒ³ã‚¬ - ã‚¸ãƒ£ãƒ³ãƒ«":
        # ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«åˆ†æ
        data = load_manga_genre_data()
        if data is None:
            st.error("ãƒãƒ³ã‚¬ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # åŸºç¤çµ±è¨ˆã®ã¿è¡¨ç¤º
        show_manga_genre_statistics_tab(data)
    
    else:
        # ãã®ä»–ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰
        menu_parts = selected_menu.split(" - ")
        if len(menu_parts) == 2:
            category = menu_parts[0]  # "ğŸ¬ ã‚¢ãƒ‹ãƒ¡" or "ğŸ“š ãƒãƒ³ã‚¬"
            item = menu_parts[1]  # "åŸä½œ", "ã‚¸ãƒ£ãƒ³ãƒ«", etc.
            st.header(f"{category} {item} åˆ†æ")
            st.info(f"{category}ã®{item}åˆ†ææ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")
        else:
            st.info("é¸æŠã•ã‚ŒãŸæ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")

if __name__ == "__main__":
    main()