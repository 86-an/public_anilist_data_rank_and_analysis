import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import os
from pathlib import Path

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AniList ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ",
    page_icon="ğŸ“Š", 
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def load_anime_data():
    """ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                a.anilist_id, a.title_romaji, a.title_native, a.format, 
                a.season, a.seasonYear, a.favorites, a.meanScore, 
                a.popularity, a.source
            FROM anime a
            WHERE a.title_romaji IS NOT NULL
            ORDER BY a.meanScore DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def get_genres_data(db_path):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        conn = sqlite3.connect(str(db_path))
        query = "SELECT DISTINCT genre_name FROM genres ORDER BY genre_name"
        cursor = conn.cursor()
        cursor.execute(query)
        genres = [row[0] for row in cursor.fetchall()]
        conn.close()
        return genres
    except sqlite3.Error as e:
        st.error(f"âŒ ã‚¸ãƒ£ãƒ³ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return []

@st.cache_data
def load_character_data():
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                c.chara_id, c.chara_name, c.favorites as char_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites as anime_favorites, 
                a.meanScore, a.format, a.source
            FROM characters c
            JOIN anime a ON c.anilist_id = a.anilist_id
            WHERE c.chara_name IS NOT NULL
            ORDER BY c.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_voiceactor_data():
    """å£°å„ªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                v.voiceactor_id, v.voiceactor_name, v.favorites as va_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites as anime_favorites, 
                a.meanScore, a.format, a.source,
                vb.voiceactor_count, vb.count_per_year
            FROM voiceactors v
            JOIN anime a ON v.anilist_id = a.anilist_id
            LEFT JOIN voiceactor_basic vb ON v.voiceactor_id = vb.voiceactor_id
            WHERE v.voiceactor_name IS NOT NULL
            ORDER BY v.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… å£°å„ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_staff_data():
    """ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                s.staff_id, s.staff_name, s.role, s.favorites as staff_favorites,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites as anime_favorites, 
                a.meanScore, a.format, a.source,
                sb.staff_count, sb.count_per_year
            FROM staff s
            JOIN anime a ON s.anilist_id = a.anilist_id
            LEFT JOIN staff_basic sb ON s.staff_id = sb.staff_id
            WHERE s.staff_name IS NOT NULL
            ORDER BY s.favorites DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_studios_data():
    """ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'anime_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ anime_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                s.studios_id, s.studios_name,
                a.anilist_id, a.title_romaji, a.title_native, 
                a.season, a.seasonYear, a.favorites as anime_favorites, 
                a.meanScore, a.format, a.source,
                sb.studios_count, sb.count_per_year
            FROM studios s
            JOIN anime a ON s.anilist_id = a.anilist_id
            LEFT JOIN studios_basic sb ON s.studios_id = sb.studios_id
            WHERE s.studios_name IS NOT NULL
            ORDER BY sb.studios_count DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        
        # studios_statsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        stats_query = """
            SELECT 
                studios_id,
                stat_type,
                total,
                avg_value
            FROM studios_stats
        """
        stats_data = pd.read_sql_query(stats_query, conn)
        conn.close()
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ”ãƒœãƒƒãƒˆã—ã¦å„studios_idã«å¯¾ã—ã¦æ¨ªå±•é–‹
        if not stats_data.empty:
            stats_pivot = stats_data.pivot_table(
                index='studios_id',
                columns='stat_type',
                values=['total', 'avg_value'],
                aggfunc='first'
            )
            
            # ã‚«ãƒ©ãƒ åã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–
            stats_pivot.columns = ['_'.join(col).strip() for col in stats_pivot.columns.values]
            stats_pivot = stats_pivot.reset_index()
            
            # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
            data = data.merge(stats_pivot, on='studios_id', how='left')
        
        st.success(f"âœ… ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_manga_data():
    """ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    try:
        # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç›¸å¯¾ãƒ‘ã‚¹ã§ã‚‚è©¦è¡Œ
        if not db_path.exists():
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            db_path = project_root / 'db' / 'manga_data.db'
        
        if not db_path.exists():
            st.error(f"âŒ manga_data.db ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.error(f"ç¢ºèªã—ãŸå ´æ‰€: {db_path}")
            return None
        
        st.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {db_path}")
        
        conn = sqlite3.connect(str(db_path))
        query = """
            SELECT 
                m.anilist_id, m.title_romaji, m.title_native, m.format,
                m.status, m.startYear, m.meanScore, m.favorites, m.popularity
            FROM manga m
            WHERE m.title_romaji IS NOT NULL
            ORDER BY m.meanScore DESC NULLS LAST
        """
        data = pd.read_sql_query(query, conn)
        conn.close()
        st.success(f"âœ… ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(data):,}ä»¶")
        return data
        
    except sqlite3.Error as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_unique_values(data, column):
    """æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—"""
    if column in data.columns:
        unique_vals = data[column].dropna().unique()
        # æ•°å€¤ã®å ´åˆã¯é™é †ã§ã‚½ãƒ¼ãƒˆã€æ–‡å­—åˆ—ã®å ´åˆã¯æ˜‡é †ã§ã‚½ãƒ¼ãƒˆ
        if pd.api.types.is_numeric_dtype(unique_vals):
            return sorted(unique_vals, reverse=True)
        else:
            return sorted(unique_vals)
    return []

def filter_data(data, filters, db_path=None):
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã¿"""
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre'] and filters['genre'] != "å…¨ã¦" and db_path:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                # è©²å½“ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ã®ã‚¢ãƒ‹ãƒ¡ãŒãªã„å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and value != "å…¨ã¦" and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    return filtered_data

def show_ranking_tab(data, genre):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header(f"ğŸ† {genre} ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x)
        )
    
    with col2:
        # å¹´åº¦é¸æŠ
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years)
        elif genre == "æ¼«ç”»" and 'startYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'startYear')]
            selected_year = st.selectbox("å¹´åº¦", years)
        else:
            selected_year = "å…¨ã¦"
    
    with col3:
        # å­£ç¯€é¸æŠï¼ˆã‚¢ãƒ‹ãƒ¡ã®ã¿ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons)
        else:
            selected_season = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5, col6 = st.columns(3)
    
    with col4:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources)
        else:
            selected_source = "å…¨ã¦"
    
    with col5:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats)
        else:
            selected_format = "å…¨ã¦"
    
    with col6:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
            
            if db_path.exists():
                available_genres = get_genres_data(db_path)
                genres_options = ["å…¨ã¦"] + available_genres
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options)
            else:
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"])
        else:
            # ãƒãƒ³ã‚¬ã®å ´åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®š
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"])
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        if selected_year != "å…¨ã¦":
            try:
                filters['seasonYear'] = float(selected_year)
            except ValueError:
                pass
        if selected_season != "å…¨ã¦":
            filters['season'] = selected_season
    elif genre == "æ¼«ç”»":
        if selected_year != "å…¨ã¦":
            try:
                filters['startYear'] = float(selected_year)
            except ValueError:
                pass
    
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
    else:
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
    
    filtered_data = filter_data(data, filters, db_path if db_path.exists() else None)
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶)")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values(selected_metric, ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        display_columns = ['title_native', 'season', 'seasonYear', 'favorites', 'meanScore', 'popularity']
        available_columns = [col for col in display_columns if col in sorted_data.columns]
        display_data = sorted_data[available_columns].copy()
        
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        column_mapping = {
            'title_native': 'ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªï¼‰',
            'season': 'å­£ç¯€',
            'seasonYear': 'å¹´åº¦',
            'favorites': 'ãŠæ°—ã«å…¥ã‚Šæ•°',
            'meanScore': 'å¹³å‡ã‚¹ã‚³ã‚¢',
            'popularity': 'äººæ°—åº¦'
        }
        
    else:  # ãƒãƒ³ã‚¬
        display_columns = ['title_native', 'startYear', 'favorites', 'meanScore', 'popularity']
        available_columns = [col for col in display_columns if col in sorted_data.columns]
        display_data = sorted_data[available_columns].copy()
        
        # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
        column_mapping = {
            'title_native': 'ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªï¼‰',
            'startYear': 'é–‹å§‹å¹´',
            'favorites': 'ãŠæ°—ã«å…¥ã‚Šæ•°',
            'meanScore': 'å¹³å‡ã‚¹ã‚³ã‚¢',
            'popularity': 'äººæ°—åº¦'
        }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if 'favorites' in display_data.columns:
        display_data['favorites'] = display_data['favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'popularity' in display_data.columns:
        display_data['popularity'] = display_data['popularity'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'meanScore' in display_data.columns:
        display_data['meanScore'] = display_data['meanScore'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ãƒãƒ£ãƒ¼ãƒˆ")
        
        top10_data = sorted_data.head(10)
        
        if not top10_data.empty:
            fig = px.bar(
                top10_data,
                x='title_romaji' if 'title_romaji' in top10_data.columns else 'title_native',
                y=selected_metric,
                title=f"ãƒˆãƒƒãƒ—10 - {metric_labels.get(selected_metric, selected_metric)}",
                labels={
                    'title_romaji': 'ã‚¿ã‚¤ãƒˆãƒ«',
                    'title_native': 'ã‚¿ã‚¤ãƒˆãƒ«',
                    selected_metric: metric_labels.get(selected_metric, selected_metric)
                }
            )
            fig.update_xaxes(tickangle=45)
            fig.update_layout(height=500)
            st.plotly_chart(fig, width='stretch')

def show_character_ranking_tab(data):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ­ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="char_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="char_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="char_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="char_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="char_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="char_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼IDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['chara_id', 'anime_favorites'], ascending=[True, False]).groupby('chara_id').first().reset_index()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values('char_favorites', ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    display_columns = ['chara_name', 'title_native', 'seasonYear', 'season', 
                      'char_favorites', 'anime_favorites', 'meanScore']
    available_columns = [col for col in display_columns if col in sorted_data.columns]
    display_data = sorted_data[available_columns].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    column_mapping = {
        'chara_name': 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å',
        'title_native': 'ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«',
        'seasonYear': 'å¹´åº¦',
        'season': 'å­£ç¯€',
        'char_favorites': 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°',
        'anime_favorites': 'ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°',
        'meanScore': 'ã‚¢ãƒ‹ãƒ¡å¹³å‡ã‚¹ã‚³ã‚¢'
    }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if 'char_favorites' in display_data.columns:
        display_data['char_favorites'] = display_data['char_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'anime_favorites' in display_data.columns:
        display_data['anime_favorites'] = display_data['anime_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'meanScore' in display_data.columns:
        display_data['meanScore'] = display_data['meanScore'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ãƒãƒ£ãƒ¼ãƒˆ")
        
        top10_data = sorted_data.head(10)
        
        if not top10_data.empty:
            fig = px.bar(
                top10_data,
                x='chara_name',
                y='char_favorites',
                title=f"ãƒˆãƒƒãƒ—10 - ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°",
                labels={
                    'chara_name': 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å',
                    'char_favorites': 'ãŠæ°—ã«å…¥ã‚Šæ•°'
                },
                hover_data=['title_native', 'seasonYear', 'season']
            )
            fig.update_xaxes(tickangle=45)
            fig.update_layout(height=500)
            st.plotly_chart(fig, width='stretch')

def show_voiceactor_ranking_tab(data):
    """å£°å„ªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ¤ å£°å„ª ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="va_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="va_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="va_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="va_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="va_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="va_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # å£°å„ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['voiceactor_id', 'anime_favorites'], ascending=[True, False]).groupby('voiceactor_id').first().reset_index()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’å£°å„ªã®ãŠæ°—ã«å…¥ã‚Šæ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values('va_favorites', ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    display_columns = ['voiceactor_name', 'title_native', 'seasonYear', 'season', 
                      'voiceactor_count', 'count_per_year', 'va_favorites', 'anime_favorites', 'meanScore']
    available_columns = [col for col in display_columns if col in sorted_data.columns]
    display_data = sorted_data[available_columns].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    column_mapping = {
        'voiceactor_name': 'å£°å„ªå',
        'title_native': 'ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«',
        'seasonYear': 'å¹´åº¦',
        'season': 'å­£ç¯€',
        'voiceactor_count': 'å£°å„ªã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'count_per_year': 'å£°å„ªå¹´å¹³å‡ã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'va_favorites': 'å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•°',
        'anime_favorites': 'ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°',
        'meanScore': 'ã‚¢ãƒ‹ãƒ¡å¹³å‡ã‚¹ã‚³ã‚¢'
    }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if 'voiceactor_count' in display_data.columns:
        display_data['voiceactor_count'] = display_data['voiceactor_count'].apply(lambda x: f"{x:,.0f}" if pd.notna(x) else "")
    if 'count_per_year' in display_data.columns:
        display_data['count_per_year'] = display_data['count_per_year'].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    if 'va_favorites' in display_data.columns:
        display_data['va_favorites'] = display_data['va_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'anime_favorites' in display_data.columns:
        display_data['anime_favorites'] = display_data['anime_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'meanScore' in display_data.columns:
        display_data['meanScore'] = display_data['meanScore'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ãƒãƒ£ãƒ¼ãƒˆ")
        
        top10_data = sorted_data.head(10)
        
        if not top10_data.empty:
            fig = px.bar(
                top10_data,
                x='voiceactor_name',
                y='va_favorites',
                title=f"ãƒˆãƒƒãƒ—10 - å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•°",
                labels={
                    'voiceactor_name': 'å£°å„ªå',
                    'va_favorites': 'ãŠæ°—ã«å…¥ã‚Šæ•°'
                },
                hover_data=['title_native', 'seasonYear', 'season']
            )
            fig.update_xaxes(tickangle=45)
            fig.update_layout(height=500)
            st.plotly_chart(fig, width='stretch')

def show_staff_ranking_tab(data):
    """ã‚¹ã‚¿ãƒƒãƒ•ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ¬ ã‚¹ã‚¿ãƒƒãƒ• ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="staff_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="staff_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="staff_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="staff_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="staff_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="staff_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ã‚¹ã‚¿ãƒƒãƒ•IDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    # ã¾ãšã€staff_idã¨anilist_idã®çµ„ã¿åˆã‚ã›ã§roleã‚’é›†ç´„
    filtered_data['roles'] = filtered_data.groupby(['staff_id', 'anilist_id'])['role'].transform(lambda x: ', '.join(sorted(set(x.dropna()))))
    
    # é‡è¤‡ã‚’å‰Šé™¤ï¼ˆstaff_idã¨anilist_idã®çµ„ã¿åˆã‚ã›ã§æœ€åˆã®è¡Œã‚’ä¿æŒï¼‰
    filtered_data = filtered_data.drop_duplicates(subset=['staff_id', 'anilist_id'], keep='first')
    
    # staff_idã”ã¨ã«ã‚¢ãƒ‹ãƒ¡favoritesãŒæœ€å¤§ã®ã‚‚ã®ã‚’é¸æŠ
    filtered_data = filtered_data.sort_values(['staff_id', 'anime_favorites'], ascending=[True, False]).groupby('staff_id').first().reset_index()
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¿ãƒƒãƒ•ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values('staff_favorites', ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    display_columns = ['staff_name', 'roles', 'title_native', 'seasonYear', 'season', 
                      'staff_count', 'count_per_year', 'staff_favorites', 'anime_favorites', 'meanScore']
    available_columns = [col for col in display_columns if col in sorted_data.columns]
    display_data = sorted_data[available_columns].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    column_mapping = {
        'staff_name': 'ã‚¹ã‚¿ãƒƒãƒ•å',
        'roles': 'å½¹å‰²',
        'title_native': 'ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«',
        'seasonYear': 'å¹´åº¦',
        'season': 'å­£ç¯€',
        'staff_count': 'ã‚¹ã‚¿ãƒƒãƒ•ã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'count_per_year': 'ã‚¹ã‚¿ãƒƒãƒ•å¹´å¹³å‡ã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'staff_favorites': 'ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•°',
        'anime_favorites': 'ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°',
        'meanScore': 'ã‚¢ãƒ‹ãƒ¡å¹³å‡ã‚¹ã‚³ã‚¢'
    }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if 'staff_count' in display_data.columns:
        display_data['staff_count'] = display_data['staff_count'].apply(lambda x: f"{x:,.0f}" if pd.notna(x) else "")
    if 'count_per_year' in display_data.columns:
        display_data['count_per_year'] = display_data['count_per_year'].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    if 'staff_favorites' in display_data.columns:
        display_data['staff_favorites'] = display_data['staff_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'anime_favorites' in display_data.columns:
        display_data['anime_favorites'] = display_data['anime_favorites'].apply(lambda x: f"{x:,}" if pd.notna(x) else "")
    if 'meanScore' in display_data.columns:
        display_data['meanScore'] = display_data['meanScore'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ãƒãƒ£ãƒ¼ãƒˆ")
        
        top10_data = sorted_data.head(10)
        
        if not top10_data.empty:
            fig = px.bar(
                top10_data,
                x='staff_name',
                y='staff_favorites',
                title=f"ãƒˆãƒƒãƒ—10 - ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•°",
                labels={
                    'staff_name': 'ã‚¹ã‚¿ãƒƒãƒ•å',
                    'staff_favorites': 'ãŠæ°—ã«å…¥ã‚Šæ•°'
                },
                hover_data=['title_native', 'seasonYear', 'season', 'roles']
            )
            fig.update_xaxes(tickangle=45)
            fig.update_layout(height=500)
            st.plotly_chart(fig, width='stretch')

def show_studios_ranking_tab(data):
    """ã‚¹ã‚¿ã‚¸ã‚ªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ¢ ã‚¹ã‚¿ã‚¸ã‚ª ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="studios_rank_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="studios_rank_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="studios_rank_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="studios_rank_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="studios_rank_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="studios_rank_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # ã‚¹ã‚¿ã‚¸ã‚ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['studios_id', 'anime_favorites'], ascending=[True, False]).groupby('studios_id').first().reset_index()
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    st.subheader(f"ğŸ“‹ ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¿ã‚¸ã‚ªã®ã‚«ã‚¦ãƒ³ãƒˆæ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_data = filtered_data.sort_values('studios_count', ascending=False).reset_index(drop=True)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æº–å‚™
    display_columns = [
        'studios_name', 'title_native', 'seasonYear', 'season', 
        'studios_count', 'count_per_year', 'anime_favorites', 'meanScore'
    ]
    
    # stat_typeåˆ¥ã®ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    stat_columns = [col for col in sorted_data.columns if col.startswith('total_') or col.startswith('avg_value_')]
    display_columns.extend(stat_columns)
    
    available_columns = [col for col in display_columns if col in sorted_data.columns]
    display_data = sorted_data[available_columns].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    column_mapping = {
        'studios_name': 'ã‚¹ã‚¿ã‚¸ã‚ªå',
        'title_native': 'ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«',
        'seasonYear': 'å¹´åº¦',
        'season': 'å­£ç¯€',
        'studios_count': 'ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°',
        'count_per_year': 'ã‚¹ã‚¿ã‚¸ã‚ªå¹´åº¦å¹³å‡å›æ•°',
        'anime_favorites': 'ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°',
        'meanScore': 'ã‚¢ãƒ‹ãƒ¡å¹³å‡ã‚¹ã‚³ã‚¢',
        'total_anime_favorites': 'anime_favoritesåˆè¨ˆ',
        'avg_value_anime_favorites': 'anime_favoriteså¹³å‡',
        'total_anime_meanScore': 'anime_meanScoreåˆè¨ˆ',
        'avg_value_anime_meanScore': 'anime_meanScoreå¹³å‡'
    }
    
    # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    numeric_columns = ['studios_count', 'count_per_year', 'anime_favorites', 'meanScore'] + stat_columns
    for col in numeric_columns:
        if col in display_data.columns:
            display_data[col] = display_data[col].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else "")
    
    # ã‚«ãƒ©ãƒ åã‚’å¤‰æ›´
    display_data = display_data.rename(columns=column_mapping)
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é †ä½ã«è¨­å®š
    display_data.index = range(1, len(display_data) + 1)
    display_data.index.name = "é †ä½"
    
    # è¡¨ç¤º
    st.dataframe(display_data, width='stretch', height=400)
    
    # ãƒˆãƒƒãƒ—10ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
    if len(sorted_data) >= 1:
        st.subheader("ğŸ“Š ãƒˆãƒƒãƒ—10ã‚¹ã‚¿ã‚¸ã‚ª")
        
        top_n = min(10, len(sorted_data))
        top_data = sorted_data.head(top_n)
        
        fig = px.bar(
            top_data,
            x='studios_count',
            y='studios_name',
            orientation='h',
            title=f"ãƒˆãƒƒãƒ—{top_n}ã‚¹ã‚¿ã‚¸ã‚ªï¼ˆä½œå“æ•°é †ï¼‰",
            labels={
                'studios_count': 'ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°',
                'studios_name': 'ã‚¹ã‚¿ã‚¸ã‚ªå'
            },
            hover_data={
                'studios_name': True,
                'title_native': True,
                'studios_count': True,
                'count_per_year': ':.2f',
                'anime_favorites': True,
                'meanScore': ':.1f'
            }
        )
        
        fig.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig, width='stretch')

def show_studios_statistics_tab(data):
    """ã‚¹ã‚¿ã‚¸ã‚ªåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“Š ã‚¹ã‚¿ã‚¸ã‚ª åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãã‚¹ã‚¿ã‚¸ã‚ªã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="studios_stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="studios_stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="studios_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="studios_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="studios_stats_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="studios_stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ã‚¸ã‚ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['studios_id', 'anime_favorites'], ascending=[True, False]).groupby('studios_id').first().reset_index()
    
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆ{len(filtered_data):,}ã‚¹ã‚¿ã‚¸ã‚ªï¼‰")
    
    # è¡¨1: studios_basicãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
    st.markdown("### ğŸ“Š è¡¨1: ã‚¹ã‚¿ã‚¸ã‚ªåŸºæœ¬çµ±è¨ˆï¼ˆstudios_basicï¼‰")
    
    basic_stats_dict = {}
    
    # studios_countçµ±è¨ˆ
    if 'studios_count' in filtered_data.columns:
        studios_count_data = filtered_data['studios_count'].dropna()
        if len(studios_count_data) > 0:
            basic_stats_dict['ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°'] = {
                'åˆè¨ˆ': f"{studios_count_data.sum():,.0f}",
                'æœ€å¤§å€¤': f"{studios_count_data.max():,.0f}",
                'æœ€å°å€¤': f"{studios_count_data.min():,.0f}",
                'å¹³å‡å€¤': f"{studios_count_data.mean():,.2f}",
                'ä¸­å¤®å€¤': f"{studios_count_data.median():,.2f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{studios_count_data.quantile(0.25):,.2f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{studios_count_data.quantile(0.75):,.2f}"
            }
    
    # first_yearçµ±è¨ˆ
    if 'first_year' in filtered_data.columns:
        first_year_data = filtered_data['first_year'].dropna()
        if len(first_year_data) > 0:
            basic_stats_dict['åˆå‡ºå¹´'] = {
                'åˆè¨ˆ': '-',
                'æœ€å¤§å€¤': f"{int(first_year_data.max())}",
                'æœ€å°å€¤': f"{int(first_year_data.min())}",
                'å¹³å‡å€¤': f"{first_year_data.mean():,.1f}",
                'ä¸­å¤®å€¤': f"{first_year_data.median():,.1f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{first_year_data.quantile(0.25):,.1f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{first_year_data.quantile(0.75):,.1f}"
            }
    
    # year_countçµ±è¨ˆ
    if 'year_count' in filtered_data.columns:
        year_count_data = filtered_data['year_count'].dropna()
        if len(year_count_data) > 0:
            basic_stats_dict['æ´»å‹•å¹´æ•°'] = {
                'åˆè¨ˆ': f"{year_count_data.sum():,.0f}",
                'æœ€å¤§å€¤': f"{year_count_data.max():,.0f}",
                'æœ€å°å€¤': f"{year_count_data.min():,.0f}",
                'å¹³å‡å€¤': f"{year_count_data.mean():,.2f}",
                'ä¸­å¤®å€¤': f"{year_count_data.median():,.2f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{year_count_data.quantile(0.25):,.2f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{year_count_data.quantile(0.75):,.2f}"
            }
    
    # count_per_yearçµ±è¨ˆ
    if 'count_per_year' in filtered_data.columns:
        count_per_year_data = filtered_data['count_per_year'].dropna()
        if len(count_per_year_data) > 0:
            basic_stats_dict['å¹´å¹³å‡ã‚«ã‚¦ãƒ³ãƒˆæ•°'] = {
                'åˆè¨ˆ': f"{count_per_year_data.sum():,.2f}",
                'æœ€å¤§å€¤': f"{count_per_year_data.max():,.2f}",
                'æœ€å°å€¤': f"{count_per_year_data.min():,.2f}",
                'å¹³å‡å€¤': f"{count_per_year_data.mean():,.4f}",
                'ä¸­å¤®å€¤': f"{count_per_year_data.median():,.4f}",
                'ç¬¬1å››åˆ†ä½æ•°': f"{count_per_year_data.quantile(0.25):,.4f}",
                'ç¬¬3å››åˆ†ä½æ•°': f"{count_per_year_data.quantile(0.75):,.4f}"
            }
    
    if basic_stats_dict:
        basic_stats_df = pd.DataFrame(basic_stats_dict)
        st.dataframe(basic_stats_df, width='stretch', height=300)
    else:
        st.info("åŸºæœ¬çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # è¡¨2: studios_statsãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆï¼ˆstat_typeåˆ¥ï¼‰
    st.markdown("### ğŸ“Š è¡¨2: ã‚¹ã‚¿ã‚¸ã‚ªçµ±è¨ˆæƒ…å ±ï¼ˆstudios_statsï¼‰")
    st.markdown("**æ³¨: ã“ã®è¡¨ã¯å…¨ã‚¹ã‚¿ã‚¸ã‚ªã®çµ±è¨ˆå€¤ï¼ˆtotal_anime_favoritesç­‰ï¼‰ã®åˆ†å¸ƒã‚’ç¤ºã—ã¦ã„ã¾ã™**")
    
    # stat_typeåˆ¥ã®ã‚«ãƒ©ãƒ ã‚’æŠ½å‡º
    stat_columns = {}
    for col in filtered_data.columns:
        if col.startswith('total_') or col.startswith('max_value_') or col.startswith('min_value_') or \
           col.startswith('avg_value_') or col.startswith('median_value_') or \
           col.startswith('q1_value_') or col.startswith('q3_value_'):
            stat_columns[col] = filtered_data[col]
    
    if stat_columns:
        stats_dict = {}
        
        # anime_favoritesã®çµ±è¨ˆ
        if 'total_anime_favorites' in stat_columns:
            fav_data = filtered_data['total_anime_favorites'].dropna()
            if len(fav_data) > 0:
                stats_dict['anime_favoritesåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{fav_data.sum():,.0f}",
                    'æœ€å¤§å€¤': f"{fav_data.max():,.0f}",
                    'æœ€å°å€¤': f"{fav_data.min():,.0f}",
                    'å¹³å‡å€¤': f"{fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{fav_data.var():,.2f}"
                }
        
        if 'avg_value_anime_favorites' in stat_columns:
            fav_avg_data = filtered_data['avg_value_anime_favorites'].dropna()
            if len(fav_avg_data) > 0:
                stats_dict['anime_favoriteså¹³å‡'] = {
                    'åˆè¨ˆ': f"{fav_avg_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{fav_avg_data.max():,.2f}",
                    'æœ€å°å€¤': f"{fav_avg_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{fav_avg_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{fav_avg_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{fav_avg_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{fav_avg_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{fav_avg_data.std():,.2f}",
                    'åˆ†æ•£': f"{fav_avg_data.var():,.2f}"
                }
        
        # anime_meanScoreã®çµ±è¨ˆ
        if 'total_anime_meanScore' in stat_columns:
            score_data = filtered_data['total_anime_meanScore'].dropna()
            if len(score_data) > 0:
                stats_dict['anime_meanScoreåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{score_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{score_data.max():,.2f}",
                    'æœ€å°å€¤': f"{score_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{score_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{score_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{score_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{score_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{score_data.std():,.2f}",
                    'åˆ†æ•£': f"{score_data.var():,.2f}"
                }
        
        if 'avg_value_anime_meanScore' in stat_columns:
            score_avg_data = filtered_data['avg_value_anime_meanScore'].dropna()
            if len(score_avg_data) > 0:
                stats_dict['anime_meanScoreå¹³å‡'] = {
                    'åˆè¨ˆ': f"{score_avg_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{score_avg_data.max():,.2f}",
                    'æœ€å°å€¤': f"{score_avg_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{score_avg_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{score_avg_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{score_avg_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{score_avg_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{score_avg_data.std():,.2f}",
                    'åˆ†æ•£': f"{score_avg_data.var():,.2f}"
                }
        
        if stats_dict:
            stats_df = pd.DataFrame(stats_dict)
            st.dataframe(stats_df, width='stretch', height=400)
        else:
            st.info("çµ±è¨ˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("çµ±è¨ˆæƒ…å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # è¡¨3: ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesçµ±è¨ˆã®è©³ç´°åˆ†æ
    st.markdown("---")
    st.markdown("### ğŸ“Š è¡¨3: ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesçµ±è¨ˆã®è©³ç´°åˆ†æ")
    st.markdown("**æ³¨: ã“ã®è¡¨ã¯ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã«é›†è¨ˆã•ã‚ŒãŸanime_favoritesåˆè¨ˆãƒ»å¹³å‡ã®çµ±è¨ˆåˆ†æã§ã™**")
    
    if 'total_anime_favorites' in filtered_data.columns or 'avg_value_anime_favorites' in filtered_data.columns:
        table3_dict = {}
        
        # ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesåˆè¨ˆã®çµ±è¨ˆ
        if 'total_anime_favorites' in filtered_data.columns:
            total_fav_data = filtered_data['total_anime_favorites'].dropna()
            if len(total_fav_data) > 0:
                table3_dict['ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoritesåˆè¨ˆ'] = {
                    'åˆè¨ˆ': f"{total_fav_data.sum():,.0f}",
                    'æœ€å¤§å€¤': f"{total_fav_data.max():,.0f}",
                    'æœ€å°å€¤': f"{total_fav_data.min():,.0f}",
                    'å¹³å‡å€¤': f"{total_fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{total_fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{total_fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{total_fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{total_fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{total_fav_data.var():,.2f}"
                }
        
        # ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoriteså¹³å‡ã®çµ±è¨ˆ
        if 'avg_value_anime_favorites' in filtered_data.columns:
            avg_fav_data = filtered_data['avg_value_anime_favorites'].dropna()
            if len(avg_fav_data) > 0:
                table3_dict['ã‚¹ã‚¿ã‚¸ã‚ªã”ã¨ã®anime_favoriteså¹³å‡'] = {
                    'åˆè¨ˆ': f"{avg_fav_data.sum():,.2f}",
                    'æœ€å¤§å€¤': f"{avg_fav_data.max():,.2f}",
                    'æœ€å°å€¤': f"{avg_fav_data.min():,.2f}",
                    'å¹³å‡å€¤': f"{avg_fav_data.mean():,.2f}",
                    'ä¸­å¤®å€¤': f"{avg_fav_data.median():,.2f}",
                    'ç¬¬1å››åˆ†ä½æ•°': f"{avg_fav_data.quantile(0.25):,.2f}",
                    'ç¬¬3å››åˆ†ä½æ•°': f"{avg_fav_data.quantile(0.75):,.2f}",
                    'æ¨™æº–åå·®': f"{avg_fav_data.std():,.2f}",
                    'åˆ†æ•£': f"{avg_fav_data.var():,.2f}"
                }
        
        if table3_dict:
            table3_df = pd.DataFrame(table3_dict)
            st.dataframe(table3_df, width='stretch', height=400)
        else:
            st.info("anime_favoritesçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("anime_favoritesçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒ
    st.markdown("---")
    st.markdown("### ğŸ“Š ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰")
    
    if 'studios_count' in filtered_data.columns:
        count_data = filtered_data['studios_count'].dropna()
        
        if len(count_data) > 0:
            # å¯¾æ•°å¤‰æ›ï¼ˆ0ã®å ´åˆã¯1ã«ç½®ãæ›ãˆï¼‰
            log_count_data = np.log10(count_data.replace(0, 1))
            
            fig = px.histogram(
                x=log_count_data,
                nbins=50,
                title="ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
                labels={'x': 'log10(ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°)', 'y': 'é »åº¦'}
            )
            
            fig.update_layout(
                showlegend=False,
                height=400,
                xaxis_title="log10(ã‚¹ã‚¿ã‚¸ã‚ªã‚«ã‚¦ãƒ³ãƒˆæ•°)",
                yaxis_title="é »åº¦"
            )
            
            st.plotly_chart(fig, width='stretch')
            
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(count_data):,}")
            with col2:
                st.metric("å¹³å‡å€¤", f"{count_data.mean():,.2f}")
            with col3:
                st.metric("ä¸­å¤®å€¤", f"{count_data.median():,.2f}")
            with col4:
                st.metric("æ¨™æº–åå·®", f"{count_data.std():,.2f}")
        else:
            st.info("ã‚«ã‚¦ãƒ³ãƒˆæ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("ã‚«ã‚¦ãƒ³ãƒˆæ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def show_voiceactor_statistics_tab(data):
    """å£°å„ªåŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“Š å£°å„ª åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãå£°å„ªã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="va_stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="va_stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="va_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="va_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="va_stats_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="va_stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # å£°å„ªIDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data = filtered_data.sort_values(['voiceactor_id', 'anime_favorites'], ascending=[True, False]).groupby('voiceactor_id').first().reset_index()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # === è¡¨1: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼favoritesçµ±è¨ˆ ===
    st.subheader("ğŸ“‹ è¡¨1: å£°å„ªã®ãŠæ°—ã«å…¥ã‚Šæ•°çµ±è¨ˆ")
    
    va_favorites_data = filtered_data['va_favorites'].dropna()
    
    if len(va_favorites_data) == 0:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯å£°å„ªã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    else:
        try:
            va_stats = {
                "åˆè¨ˆ": float(va_favorites_data.sum()),
                "ã‚«ã‚¦ãƒ³ãƒˆ": len(va_favorites_data),
                "æœ€å¤§": float(va_favorites_data.max()),
                "æœ€å°": float(va_favorites_data.min()),
                "å¹³å‡": float(va_favorites_data.mean()),
                "ä¸­å¤®å€¤": float(va_favorites_data.median()),
                "1/4åˆ†ä½": float(va_favorites_data.quantile(0.25)),
                "3/4åˆ†ä½": float(va_favorites_data.quantile(0.75))
            }
            
            if len(va_favorites_data) > 1:
                va_stats["æ¨™æº–åå·®"] = float(va_favorites_data.std())
                va_stats["åˆ†æ•£"] = float(va_favorites_data.var())
            else:
                va_stats["æ¨™æº–åå·®"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
                va_stats["åˆ†æ•£"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
            
            va_stats_df = pd.DataFrame(
                [(key, value) for key, value in va_stats.items()],
                columns=["çµ±è¨ˆé …ç›®", "å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•°"]
            )
            st.dataframe(va_stats_df, width='stretch', height=400)
            
        except Exception as e:
            st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # === è¡¨2: ã‚¢ãƒ‹ãƒ¡favoritesçµ±è¨ˆ ===
    st.subheader("ğŸ“‹ è¡¨2: ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°çµ±è¨ˆ")
    
    anime_favorites_data = filtered_data['anime_favorites'].dropna()
    
    if len(anime_favorites_data) == 0:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯ã‚¢ãƒ‹ãƒ¡ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    else:
        try:
            anime_fav_stats = {
                "åˆè¨ˆ": float(anime_favorites_data.sum()),
                "ã‚«ã‚¦ãƒ³ãƒˆ": len(anime_favorites_data),
                "æœ€å¤§": float(anime_favorites_data.max()),
                "æœ€å°": float(anime_favorites_data.min()),
                "å¹³å‡": float(anime_favorites_data.mean()),
                "ä¸­å¤®å€¤": float(anime_favorites_data.median()),
                "1/4åˆ†ä½": float(anime_favorites_data.quantile(0.25)),
                "3/4åˆ†ä½": float(anime_favorites_data.quantile(0.75))
            }
            
            if len(anime_favorites_data) > 1:
                anime_fav_stats["æ¨™æº–åå·®"] = float(anime_favorites_data.std())
                anime_fav_stats["åˆ†æ•£"] = float(anime_favorites_data.var())
            else:
                anime_fav_stats["æ¨™æº–åå·®"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
                anime_fav_stats["åˆ†æ•£"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
            
            anime_fav_stats_df = pd.DataFrame(
                [(key, value) for key, value in anime_fav_stats.items()],
                columns=["çµ±è¨ˆé …ç›®", "ã‚¢ãƒ‹ãƒ¡ãŠæ°—ã«å…¥ã‚Šæ•°"]
            )
            st.dataframe(anime_fav_stats_df, width='stretch', height=400)
            
        except Exception as e:
            st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # === ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•°ã®åˆ†å¸ƒ ===
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰")
    if len(va_favorites_data) > 0:
        # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¯¾æ•°å¤‰æ›
        log_data = np.log10(va_favorites_data[va_favorites_data > 0])  # 0ã‚ˆã‚Šå¤§ãã„å€¤ã®ã¿å¯¾æ•°å¤‰æ›
        
        fig_hist = px.histogram(
            x=log_data,
            nbins=30,
            title="å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
            labels={
                'x': 'å£°å„ªãŠæ°—ã«å…¥ã‚Šæ•° (log10)',
                'y': 'é »åº¦'
            }
        )
        
        # yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«è¨­å®š
        fig_hist.update_yaxes(type="log")
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')

def show_staff_statistics_tab(data):
    """ã‚¹ã‚¿ãƒƒãƒ•åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“Š ã‚¹ã‚¿ãƒƒãƒ• åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãã‚¹ã‚¿ãƒƒãƒ•ã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="staff_stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="staff_stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="staff_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="staff_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="staff_stats_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="staff_stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¹ã‚¿ãƒƒãƒ•IDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€ã‚¢ãƒ‹ãƒ¡ã®favoritesãŒæœ€ã‚‚å¤šã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    # ã¾ãšã€staff_idã¨anilist_idã®çµ„ã¿åˆã‚ã›ã§roleã‚’é›†ç´„
    filtered_data['roles'] = filtered_data.groupby(['staff_id', 'anilist_id'])['role'].transform(lambda x: ', '.join(sorted(set(x.dropna()))))
    
    # é‡è¤‡ã‚’å‰Šé™¤ï¼ˆstaff_idã¨anilist_idã®çµ„ã¿åˆã‚ã›ã§æœ€åˆã®è¡Œã‚’ä¿æŒï¼‰
    filtered_data = filtered_data.drop_duplicates(subset=['staff_id', 'anilist_id'], keep='first')
    
    # staff_idã”ã¨ã«ã‚¢ãƒ‹ãƒ¡favoritesãŒæœ€å¤§ã®ã‚‚ã®ã‚’é¸æŠ
    filtered_data = filtered_data.sort_values(['staff_id', 'anime_favorites'], ascending=[True, False]).groupby('staff_id').first().reset_index()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # === è¡¨1: ã‚¹ã‚¿ãƒƒãƒ•favoritesçµ±è¨ˆ ===
    st.subheader("ğŸ“‹ è¡¨1: ã‚¹ã‚¿ãƒƒãƒ•ã®ãŠæ°—ã«å…¥ã‚Šæ•°çµ±è¨ˆ")
    
    staff_favorites_data = filtered_data['staff_favorites'].dropna()
    
    if len(staff_favorites_data) == 0:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯ã‚¹ã‚¿ãƒƒãƒ•ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
    else:
        try:
            staff_stats = {
                "åˆè¨ˆ": float(staff_favorites_data.sum()),
                "ã‚«ã‚¦ãƒ³ãƒˆ": len(staff_favorites_data),
                "æœ€å¤§": float(staff_favorites_data.max()),
                "æœ€å°": float(staff_favorites_data.min()),
                "å¹³å‡": float(staff_favorites_data.mean()),
                "ä¸­å¤®å€¤": float(staff_favorites_data.median()),
                "1/4åˆ†ä½": float(staff_favorites_data.quantile(0.25)),
                "3/4åˆ†ä½": float(staff_favorites_data.quantile(0.75))
            }
            
            if len(staff_favorites_data) > 1:
                staff_stats["æ¨™æº–åå·®"] = float(staff_favorites_data.std())
                staff_stats["åˆ†æ•£"] = float(staff_favorites_data.var())
            else:
                staff_stats["æ¨™æº–åå·®"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
                staff_stats["åˆ†æ•£"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
            
            staff_stats_df = pd.DataFrame(
                [(key, value) for key, value in staff_stats.items()],
                columns=["çµ±è¨ˆé …ç›®", "ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•°"]
            )
            st.dataframe(staff_stats_df, width='stretch', height=400)
            
        except Exception as e:
            st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # === è¡¨2: staff_basic ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã®çµ±è¨ˆ ===
    st.subheader("ğŸ“‹ è¡¨2: ã‚¹ã‚¿ãƒƒãƒ•åŸºæœ¬çµ±è¨ˆï¼ˆstaff_basicãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰")
    
    try:
        conn = sqlite3.connect(str(db_path))
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸstaff_idã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        staff_ids = filtered_data['staff_id'].unique().tolist()
        
        if len(staff_ids) > 0:
            # staff_basicãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            placeholders = ','.join(['?'] * len(staff_ids))
            query = f"""
                SELECT 
                    staff_id,
                    staff_name,
                    favorites,
                    staff_count,
                    first_year,
                    year_count,
                    count_per_year
                FROM staff_basic
                WHERE staff_id IN ({placeholders})
            """
            
            staff_basic_df = pd.read_sql_query(query, conn, params=staff_ids)
            
            if not staff_basic_df.empty:
                # å„ã‚«ãƒ©ãƒ ã®çµ±è¨ˆã‚’è¨ˆç®—
                basic_stats = {
                    "ã‚¹ã‚¿ãƒƒãƒ•æ•°": len(staff_basic_df),
                    "favoritesåˆè¨ˆ": float(staff_basic_df['favorites'].sum()),
                    "favoriteså¹³å‡": float(staff_basic_df['favorites'].mean()),
                    "favoritesä¸­å¤®å€¤": float(staff_basic_df['favorites'].median()),
                    "staff_countåˆè¨ˆ": float(staff_basic_df['staff_count'].sum()),
                    "staff_countå¹³å‡": float(staff_basic_df['staff_count'].mean()),
                    "æœ€å¤ã®å¹´åº¦": int(staff_basic_df['first_year'].min()),
                    "æœ€æ–°ã®å¹´åº¦": int(staff_basic_df['first_year'].max()),
                    "å¹´é–“å¹³å‡ä½œå“æ•°ï¼ˆå¹³å‡ï¼‰": float(staff_basic_df['count_per_year'].mean())
                }
                
                basic_stats_df = pd.DataFrame(
                    [(key, value) for key, value in basic_stats.items()],
                    columns=["çµ±è¨ˆé …ç›®", "å€¤"]
                )
                st.dataframe(basic_stats_df, width='stretch', height=400)
            else:
                st.warning("staff_basicãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ã‚¹ã‚¿ãƒƒãƒ•IDãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        conn.close()
        
    except Exception as e:
        st.error(f"staff_basicãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # === ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ : ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•°ã®åˆ†å¸ƒ ===
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰")
    if len(staff_favorites_data) > 0:
        # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¯¾æ•°å¤‰æ›
        log_data = np.log10(staff_favorites_data[staff_favorites_data > 0])  # 0ã‚ˆã‚Šå¤§ãã„å€¤ã®ã¿å¯¾æ•°å¤‰æ›
        
        fig_hist = px.histogram(
            x=log_data,
            nbins=30,
            title="ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
            labels={
                'x': 'ã‚¹ã‚¿ãƒƒãƒ•ãŠæ°—ã«å…¥ã‚Šæ•° (log10)',
                'y': 'é »åº¦'
            }
        )
        
        # yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«è¨­å®š
        fig_hist.update_yaxes(type="log")
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')

def show_character_statistics_tab(data):
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header("ğŸ“Š ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®åŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="char_stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠ
        if 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="char_stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="char_stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="char_stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
        
        if db_path.exists():
            available_genres = get_genres_data(db_path)
            genres_options = ["å…¨ã¦"] + available_genres
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="char_stats_genre")
        else:
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="char_stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if selected_year != "å…¨ã¦":
        try:
            filters['seasonYear'] = float(selected_year)
        except ValueError:
            pass
    if selected_season != "å…¨ã¦":
        filters['season'] = selected_season
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯anilist_idãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼‰
    filtered_data = data.copy()
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å‡¦ç†
    if 'genre' in filters and filters['genre']:
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT anilist_id 
                FROM genres 
                WHERE genre_name = ?
            """, (filters['genre'],))
            genre_anime_ids = [row[0] for row in cursor.fetchall()]
            conn.close()
            
            if genre_anime_ids:
                filtered_data = filtered_data[filtered_data['anilist_id'].isin(genre_anime_ids)]
            else:
                filtered_data = filtered_data.iloc[0:0]
        except Exception as e:
            st.error(f"ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
    for key, value in filters.items():
        if key != 'genre' and value and key in filtered_data.columns:
            filtered_data = filtered_data[filtered_data[key] == value]
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼IDãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã€æœ€ã‚‚çŸ­ã„ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚‚ã®ã ã‘ã‚’æ®‹ã™
    filtered_data['title_length'] = filtered_data['title_native'].str.len()
    filtered_data = filtered_data.sort_values(['chara_id', 'title_length']).groupby('chara_id').first().reset_index()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ ({filtered_count:,}ä»¶ï¼‰")
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Šæ•°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    metric_data = filtered_data['char_favorites'].dropna()
    
    if len(metric_data) == 0:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Šæ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return
    
    # åŸºç¤çµ±è¨ˆã®è¨ˆç®—
    try:
        stats = {
            "åˆè¨ˆ": float(metric_data.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": len(metric_data),
            "æœ€å¤§": float(metric_data.max()),
            "æœ€å°": float(metric_data.min()),
            "å¹³å‡": float(metric_data.mean()),
            "ä¸­å¤®å€¤": float(metric_data.median()),
            "1/4åˆ†ä½": float(metric_data.quantile(0.25)),
            "3/4åˆ†ä½": float(metric_data.quantile(0.75))
        }
        
        # æ¨™æº–åå·®ã¨åˆ†æ•£ï¼ˆè¨ˆç®—ã§ããªã„å ´åˆã®å‡¦ç†ï¼‰
        if len(metric_data) > 1:
            stats["æ¨™æº–åå·®"] = float(metric_data.std())
            stats["åˆ†æ•£"] = float(metric_data.var())
        else:
            stats["æ¨™æº–åå·®"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
            stats["åˆ†æ•£"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
        
    except Exception as e:
        st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # çµ±è¨ˆè¡¨ã®è¡¨ç¤º
    st.subheader("ğŸ“‹ åŸºç¤çµ±è¨ˆè¡¨")
    stats_df = pd.DataFrame(
        [(key, value) for key, value in stats.items()],
        columns=["çµ±è¨ˆé …ç›®", "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°"]
    )
    st.dataframe(stats_df, width='stretch', height=400)
    
    # è¨ˆç®—ã§ããªã‹ã£ãŸé …ç›®ã®è¡¨ç¤º
    non_numeric_stats = {k: v for k, v in stats.items() if not isinstance(v, (int, float))}
    if non_numeric_stats:
        st.subheader("âš ï¸ è¨ˆç®—ã§ããªã„é …ç›®")
        for item, reason in non_numeric_stats.items():
            st.warning(f"**{item}**: {reason}")
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤º
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰")
    if len(metric_data) > 0:
        # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¯¾æ•°å¤‰æ›
        log_data = np.log10(metric_data[metric_data > 0])  # 0ã‚ˆã‚Šå¤§ãã„å€¤ã®ã¿å¯¾æ•°å¤‰æ›
        
        fig_hist = px.histogram(
            x=log_data,
            nbins=30,
            title="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•°ã®åˆ†å¸ƒï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
            labels={
                'x': 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŠæ°—ã«å…¥ã‚Šæ•° (log10)',
                'y': 'é »åº¦'
            }
        )
        
        # yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«è¨­å®š
        fig_hist.update_yaxes(type="log")
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')

def show_statistics_tab(data, genre):
    """åŸºç¤çµ±è¨ˆã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header(f"ğŸ“Š {genre} åŸºç¤çµ±è¨ˆ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ãåŸºç¤çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # æŒ‡æ¨™é¸æŠ
        metric_options = ["meanScore", "favorites", "popularity"]
        metric_labels = {
            "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
            "favorites": "ãŠæ°—ã«å…¥ã‚Šæ•°", 
            "popularity": "äººæ°—åº¦"
        }
        selected_metric = st.selectbox(
            "æŒ‡æ¨™",
            metric_options,
            format_func=lambda x: metric_labels.get(x, x),
            key="stats_metric"
        )
    
    with col2:
        # å¹´åº¦é¸æŠ
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'seasonYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="stats_year")
        elif genre == "æ¼«ç”»" and 'startYear' in data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(data, 'startYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="stats_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col3:
        # å­£ç¯€é¸æŠï¼ˆã‚¢ãƒ‹ãƒ¡ã®ã¿ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'season' in data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="stats_season")
        else:
            selected_season = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5, col6 = st.columns(3)
    
    with col4:
        # åŸä½œé¸æŠ
        if 'source' in data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="stats_source")
        else:
            selected_source = "å…¨ã¦"
    
    with col5:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="stats_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col6:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            # çµ¶å¯¾ãƒ‘ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´æ‰€ã‚’æŒ‡å®š
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
            
            if db_path.exists():
                available_genres = get_genres_data(db_path)
                genres_options = ["å…¨ã¦"] + available_genres
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="stats_genre")
            else:
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="stats_genre")
        else:
            # ãƒãƒ³ã‚¬ã®å ´åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®š
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="stats_genre")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        if selected_year != "å…¨ã¦":
            try:
                filters['seasonYear'] = float(selected_year)
            except ValueError:
                pass
        if selected_season != "å…¨ã¦":
            filters['season'] = selected_season
    elif genre == "æ¼«ç”»":
        if selected_year != "å…¨ã¦":
            try:
                filters['startYear'] = float(selected_year)
            except ValueError:
                pass
    
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
    else:
        db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\manga_data.db')
    
    filtered_data = filter_data(data, filters, db_path if db_path.exists() else None)
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
    filtered_count = len(filtered_data)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    st.subheader(f"ğŸ“ˆ çµ±è¨ˆåˆ†æçµæœ ({filtered_count:,}ä»¶)")
    
    # é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    metric_data = filtered_data[selected_metric].dropna()
    
    if len(metric_data) == 0:
        st.error(f"é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ã¯{metric_labels.get(selected_metric, selected_metric)}ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return
    
    # åŸºç¤çµ±è¨ˆã®è¨ˆç®—
    try:
        stats = {
            "åˆè¨ˆ": float(metric_data.sum()),
            "ã‚«ã‚¦ãƒ³ãƒˆ": len(metric_data),
            "æœ€å¤§": float(metric_data.max()),
            "æœ€å°": float(metric_data.min()),
            "å¹³å‡": float(metric_data.mean()),
            "ä¸­å¤®å€¤": float(metric_data.median()),
            "1/4åˆ†ä½": float(metric_data.quantile(0.25)),
            "3/4åˆ†ä½": float(metric_data.quantile(0.75))
        }
        
        # æ¨™æº–åå·®ã¨åˆ†æ•£ï¼ˆè¨ˆç®—ã§ããªã„å ´åˆã®å‡¦ç†ï¼‰
        if len(metric_data) > 1:
            stats["æ¨™æº–åå·®"] = float(metric_data.std())
            stats["åˆ†æ•£"] = float(metric_data.var())
        else:
            stats["æ¨™æº–åå·®"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
            stats["åˆ†æ•£"] = "è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ï¼‰"
        
    except Exception as e:
        st.error(f"çµ±è¨ˆè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # çµ±è¨ˆè¡¨ã®è¡¨ç¤º
    st.subheader("ğŸ“‹ åŸºç¤çµ±è¨ˆè¡¨")
    stats_df = pd.DataFrame(
        [(key, value) for key, value in stats.items()],
        columns=["çµ±è¨ˆé …ç›®", metric_labels.get(selected_metric, selected_metric)]
    )
    st.dataframe(stats_df, width='stretch', height=400)
    
    # è¨ˆç®—ã§ããªã‹ã£ãŸé …ç›®ã®è¡¨ç¤º
    non_numeric_stats = {k: v for k, v in stats.items() if not isinstance(v, (int, float))}
    if non_numeric_stats:
        st.subheader("âš ï¸ è¨ˆç®—ã§ããªã„é …ç›®")
        for item, reason in non_numeric_stats.items():
            st.warning(f"**{item}**: {reason}")
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ è¡¨ç¤º
    st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰")
    if len(metric_data) > 0:
        fig_hist = px.histogram(
            x=metric_data,
            nbins=30,
            title=f"{metric_labels.get(selected_metric, selected_metric)} ã®åˆ†å¸ƒ",
            labels={
                'x': metric_labels.get(selected_metric, selected_metric),
                'y': 'é »åº¦'
            }
        )
        fig_hist.update_layout(height=400)
        st.plotly_chart(fig_hist, width='stretch')



def show_scatter_tab(data, genre):
    """ç›¸é–¢åˆ†æã‚¿ãƒ–ã®è¡¨ç¤º"""
    st.header(f"ğŸ” {genre} ç›¸é–¢åˆ†æ")
    st.markdown("**ã“ã®ã‚¿ãƒ–ã§ã¯é¸æŠã•ã‚ŒãŸ2ã¤ã®æŒ‡æ¨™é–“ã®ç›¸é–¢é–¢ä¿‚ã‚’åˆ†æã—ã¾ã™**")
    
    if data is None or data.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã‚«ãƒ©ãƒ ã‚’ã‚¯ã‚¨ãƒªã«è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å†å–å¾—
    try:
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            db_path = Path(r'C:\Users\PC_User\Desktop\GitHub\public_anilist_data_rank_and_analysis\db\anime_data.db')
            conn = sqlite3.connect(str(db_path))
            query = """
                SELECT 
                    a.anilist_id, a.title_romaji, a.title_native, a.format, 
                    a.season, a.seasonYear, a.favorites, a.meanScore, 
                    a.popularity, a.source, a.episode
                FROM anime a
                WHERE a.title_romaji IS NOT NULL
            """
            extended_data = pd.read_sql_query(query, conn)
            conn.close()
        else:
            extended_data = data.copy()
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        extended_data = data.copy()
    
    # é¸æŠè‚¢ã®å®šç¾©
    categorical_options = {
        "format": "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ",
        "season": "ã‚·ãƒ¼ã‚ºãƒ³", 
        "seasonYear": "å¹´åº¦",
        "source": "ã‚½ãƒ¼ã‚¹"
    }
    
    numerical_options = {
        "episode": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°",
        "favorites": "ãŠæ°—ã«å…¥ã‚Š",
        "meanScore": "å¹³å‡ã‚¹ã‚³ã‚¢",
        "popularity": "äººæ°—åº¦"
    }
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        try:
            available_genres = get_genres_data(db_path)
            if available_genres:
                categorical_options["genre"] = "ã‚¸ãƒ£ãƒ³ãƒ«"
        except:
            pass
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
    st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # å¹´åº¦é¸æŠ
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'seasonYear' in extended_data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(extended_data, 'seasonYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="corr_year")
        elif genre == "æ¼«ç”»" and 'startYear' in extended_data.columns:
            years = ["å…¨ã¦"] + [str(int(year)) for year in get_unique_values(extended_data, 'startYear')]
            selected_year = st.selectbox("å¹´åº¦", years, key="corr_year")
        else:
            selected_year = "å…¨ã¦"
    
    with col2:
        # å­£ç¯€é¸æŠï¼ˆã‚¢ãƒ‹ãƒ¡ã®ã¿ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡" and 'season' in extended_data.columns:
            seasons = ["å…¨ã¦"] + get_unique_values(extended_data, 'season')
            selected_season = st.selectbox("å­£ç¯€", seasons, key="corr_season")
        else:
            selected_season = "å…¨ã¦"
    
    with col3:
        # åŸä½œé¸æŠ
        if 'source' in extended_data.columns:
            sources = ["å…¨ã¦"] + get_unique_values(extended_data, 'source')
            selected_source = st.selectbox("åŸä½œ", sources, key="corr_source")
        else:
            selected_source = "å…¨ã¦"
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    col4, col5 = st.columns(2)
    
    with col4:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé¸æŠ
        if 'format' in extended_data.columns:
            formats = ["å…¨ã¦"] + get_unique_values(extended_data, 'format')
            selected_format = st.selectbox("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", formats, key="corr_format")
        else:
            selected_format = "å…¨ã¦"
    
    with col5:
        # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        if genre == "ã‚¢ãƒ‹ãƒ¡":
            try:
                available_genres = get_genres_data(db_path)
                genres_options = ["å…¨ã¦"] + available_genres
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", genres_options, key="corr_genre_filter")
            except:
                selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="corr_genre_filter")
        else:
            # ãƒãƒ³ã‚¬ã®å ´åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®š
            selected_genre_filter = st.selectbox("ã‚¸ãƒ£ãƒ³ãƒ«", ["å…¨ã¦"], key="corr_genre_filter")
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filters = {}
    if genre == "ã‚¢ãƒ‹ãƒ¡":
        if selected_year != "å…¨ã¦":
            try:
                filters['seasonYear'] = float(selected_year)
            except ValueError:
                pass
        if selected_season != "å…¨ã¦":
            filters['season'] = selected_season
    elif genre == "æ¼«ç”»":
        if selected_year != "å…¨ã¦":
            try:
                filters['startYear'] = float(selected_year)
            except ValueError:
                pass
    
    if selected_source != "å…¨ã¦":
        filters['source'] = selected_source
    if selected_format != "å…¨ã¦":
        filters['format'] = selected_format
    if selected_genre_filter != "å…¨ã¦":
        filters['genre'] = selected_genre_filter
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_data = filter_data(extended_data, filters, db_path if db_path.exists() else None)
    
    if filtered_data.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’è¡¨ç¤º
    filtered_count = len(filtered_data)
    st.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {filtered_count:,}ä»¶")
    
    # ç›¸é–¢åˆ†æè¨­å®š
    st.subheader("ğŸ”§ ç›¸é–¢åˆ†æè¨­å®š")
    
    # åˆ†æãƒ¢ãƒ¼ãƒ‰é¸æŠ
    analysis_mode = st.radio(
        "åˆ†æãƒ¢ãƒ¼ãƒ‰",
        ["å˜ä¸€ç›¸é–¢åˆ†æ", "è¤‡æ•°ç›¸é–¢åˆ†æ"],
        key="analysis_mode",
        horizontal=True
    )
    
    if analysis_mode == "å˜ä¸€ç›¸é–¢åˆ†æ":
        # å˜ä¸€ç›¸é–¢åˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            # é¸æŠè‚¢1ï¼ˆæ•°å€¤ã®ã¿ï¼‰
            selected_var1 = st.selectbox(
                "é¸æŠè‚¢1ï¼ˆæ•°å€¤é …ç›®ï¼‰",
                list(numerical_options.keys()),
                format_func=lambda x: numerical_options.get(x, x),
                key="single_var1"
            )
        
        with col2:
            # é¸æŠè‚¢2ï¼ˆæ•°å€¤ã®ã¿ï¼‰
            selected_var2 = st.selectbox(
                "é¸æŠè‚¢2ï¼ˆæ•°å€¤é …ç›®ï¼‰",
                list(numerical_options.keys()),
                format_func=lambda x: numerical_options.get(x, x),
                key="single_var2"
            )
        
        # å˜ä¸€ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
        if selected_var1 != selected_var2:
            show_numerical_correlation(filtered_data, selected_var1, selected_var2, numerical_options, numerical_options)
        else:
            st.warning("åŒã˜é …ç›®åŒå£«ã®ç›¸é–¢ã¯åˆ†æã§ãã¾ã›ã‚“ã€‚ç•°ãªã‚‹é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    
    else:
        # è¤‡æ•°ç›¸é–¢åˆ†æ
        st.markdown("**è¤‡æ•°é …ç›®é–“ã®ç›¸é–¢ä¿‚æ•°ã‚’ä¸€åº¦ã«è¡¨ç¤ºã—ã¾ã™**")
        
        # åˆ†æå¯¾è±¡é …ç›®ã®é¸æŠ
        selected_vars = st.multiselect(
            "åˆ†æã™ã‚‹é …ç›®ã‚’é¸æŠï¼ˆ2ã¤ä»¥ä¸Šï¼‰",
            list(numerical_options.keys()),
            default=list(numerical_options.keys())[:3],  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®3é …ç›®ã‚’é¸æŠ
            format_func=lambda x: numerical_options.get(x, x),
            key="multi_vars"
        )
        
        if len(selected_vars) < 2:
            st.warning("2ã¤ä»¥ä¸Šã®é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            # è¤‡æ•°ç›¸é–¢åˆ†æã®å®Ÿè¡Œ
            show_multiple_correlation(filtered_data, selected_vars, numerical_options)

def show_numerical_correlation(data, var1, var2, options1, options2):
    """æ•°å€¤å¤‰æ•°åŒå£«ã®ç›¸é–¢åˆ†æ"""
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    clean_data = data[[var1, var2, 'title_romaji']].dropna()
    
    if len(clean_data) < 2:
        st.error("ç›¸é–¢åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—
    correlation = clean_data[var1].corr(clean_data[var2])
    
    # æ•£å¸ƒå›³ã®ä½œæˆï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    fig = px.scatter(
        clean_data,
        x=var1,
        y=var2,
        hover_name='title_romaji',
        title=f"{options1.get(var1)} vs {options2.get(var2)} ã®ç›¸é–¢åˆ†æï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰",
        labels={
            var1: options1.get(var1),
            var2: options2.get(var2)
        },
        log_x=True,
        log_y=True
    )
    
    # å›å¸°ç·šã®è¿½åŠ ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    try:
        fig.add_traces(
            px.scatter(clean_data, x=var1, y=var2, trendline="ols", log_x=True, log_y=True).data[1:]
        )
    except:
        # å›å¸°ç·šã®è¿½åŠ ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        pass
    
    fig.update_layout(height=500)
    st.plotly_chart(fig, width='stretch')
    
    # ç›¸é–¢ä¿‚æ•°ã‚’æ•£å¸ƒå›³ã®ä¸‹ã«è¡¨ç¤º
    st.subheader("ğŸ“Š ç›¸é–¢ä¿‚æ•°")
    
    # ç›¸é–¢ä¿‚æ•°
    st.metric("ç›¸é–¢ä¿‚æ•°", f"{correlation:.4f}")
    
    # ç›¸é–¢ã®å¼·ã•åˆ¤å®š
    abs_corr = abs(correlation)
    if abs_corr >= 0.8:
        strength = "éå¸¸ã«å¼·ã„"
        color = "ğŸ”´"
    elif abs_corr >= 0.6:
        strength = "å¼·ã„"
        color = "ğŸŸ "
    elif abs_corr >= 0.4:
        strength = "ä¸­ç¨‹åº¦"
        color = "ğŸŸ¡"
    elif abs_corr >= 0.2:
        strength = "å¼±ã„"
        color = "ğŸŸ¢"
    else:
        strength = "éå¸¸ã«å¼±ã„"
        color = "âšª"
    
    st.metric("ç›¸é–¢ã®å¼·ã•", f"{color} {strength}")
    
    # ç›¸é–¢ã®æ–¹å‘
    direction = "æ­£ã®ç›¸é–¢" if correlation > 0 else "è² ã®ç›¸é–¢"
    st.metric("ç›¸é–¢ã®æ–¹å‘", direction)
    
    # ãƒ‡ãƒ¼ã‚¿æ•°
    st.metric("åˆ†æãƒ‡ãƒ¼ã‚¿æ•°", f"{len(clean_data):,}ä»¶")

def show_multiple_correlation(data, selected_vars, numerical_options):
    """è¤‡æ•°å¤‰æ•°é–“ã®ç›¸é–¢åˆ†æ"""
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    analysis_columns = selected_vars + ['title_romaji']
    clean_data = data[analysis_columns].dropna()
    
    if len(clean_data) < 2:
        st.error("ç›¸é–¢åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
    corr_matrix = clean_data[selected_vars].corr()
    
    # ç›¸é–¢è¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    st.subheader("ğŸ“Š ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    
    fig_heatmap = px.imshow(
        corr_matrix,
        labels=dict(x="é …ç›®", y="é …ç›®", color="ç›¸é–¢ä¿‚æ•°"),
        x=[numerical_options.get(var, var) for var in selected_vars],
        y=[numerical_options.get(var, var) for var in selected_vars],
        color_continuous_scale="RdBu",
        aspect="auto",
        title="ç›¸é–¢ä¿‚æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
    )
    
    # ç›¸é–¢ä¿‚æ•°ã‚’å„ã‚»ãƒ«ã«è¡¨ç¤º
    for i in range(len(selected_vars)):
        for j in range(len(selected_vars)):
            fig_heatmap.add_annotation(
                x=j, y=i,
                text=f"{corr_matrix.iloc[i, j]:.3f}",
                showarrow=False,
                font=dict(color="white" if abs(corr_matrix.iloc[i, j]) > 0.5 else "black")
            )
    
    fig_heatmap.update_layout(height=500)
    st.plotly_chart(fig_heatmap, width='stretch')
    
    # å€‹åˆ¥ã®æ•£å¸ƒå›³ï¼ˆå¼·ã„ç›¸é–¢ã®ãƒšã‚¢ã®ã¿ï¼‰
    st.subheader("ğŸ” ä¸»è¦ãªç›¸é–¢é–¢ä¿‚ã®æ•£å¸ƒå›³")
    
    # å¼·ã„ç›¸é–¢ï¼ˆçµ¶å¯¾å€¤0.3ä»¥ä¸Šï¼‰ã®ãƒšã‚¢ã‚’æŠ½å‡º
    strong_correlations = []
    for i in range(len(selected_vars)):
        for j in range(i+1, len(selected_vars)):
            corr_value = corr_matrix.iloc[i, j]
            if abs(corr_value) >= 0.3:
                strong_correlations.append({
                    'var1': selected_vars[i],
                    'var2': selected_vars[j],
                    'correlation': corr_value,
                    'abs_correlation': abs(corr_value)
                })
    
    # ç›¸é–¢ã®å¼·ã•ã§ã‚½ãƒ¼ãƒˆ
    strong_correlations.sort(key=lambda x: x['abs_correlation'], reverse=True)
    
    if not strong_correlations:
        st.info("ç›¸é–¢ä¿‚æ•°ã®çµ¶å¯¾å€¤ãŒ0.3ä»¥ä¸Šã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("ã™ã¹ã¦ã®ãƒšã‚¢ã®ç›¸é–¢ä¿‚æ•°ã¯ä¸Šã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§ç¢ºèªã§ãã¾ã™ã€‚")
    else:
        # ä¸Šä½ã®ç›¸é–¢ãƒšã‚¢ã®æ•£å¸ƒå›³ã‚’è¡¨ç¤ºï¼ˆæœ€å¤§3ãƒšã‚¢ï¼‰
        for idx, corr_info in enumerate(strong_correlations[:3]):
            var1, var2 = corr_info['var1'], corr_info['var2']
            correlation = corr_info['correlation']
            
            st.write(f"**{numerical_options.get(var1)} vs {numerical_options.get(var2)}**")
            
            # æ•£å¸ƒå›³ã®ä½œæˆï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            pair_data = clean_data[[var1, var2, 'title_romaji']].dropna()
            
            if len(pair_data) >= 2:
                fig = px.scatter(
                    pair_data,
                    x=var1,
                    y=var2,
                    hover_name='title_romaji',
                    labels={
                        var1: numerical_options.get(var1),
                        var2: numerical_options.get(var2)
                    },
                    log_x=True,
                    log_y=True
                )
                
                # å›å¸°ç·šã®è¿½åŠ ï¼ˆå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
                try:
                    fig.add_traces(
                        px.scatter(pair_data, x=var1, y=var2, trendline="ols", log_x=True, log_y=True).data[1:]
                    )
                except:
                    # å›å¸°ç·šã®è¿½åŠ ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, width='stretch')
                
                # ç›¸é–¢ä¿‚æ•°ã‚’è¡¨ç¤º
                st.metric("ç›¸é–¢ä¿‚æ•°", f"{correlation:.4f}")
                
                # ç›¸é–¢ã®å¼·ã•åˆ¤å®š
                abs_corr = abs(correlation)
                if abs_corr >= 0.8:
                    strength = "éå¸¸ã«å¼·ã„"
                    color = "ğŸ”´"
                elif abs_corr >= 0.6:
                    strength = "å¼·ã„"
                    color = "ğŸŸ "
                elif abs_corr >= 0.4:
                    strength = "ä¸­ç¨‹åº¦"
                    color = "ğŸŸ¡"
                elif abs_corr >= 0.2:
                    strength = "å¼±ã„"
                    color = "ğŸŸ¢"
                else:
                    strength = "éå¸¸ã«å¼±ã„"
                    color = "âšª"
                
                st.metric("ç›¸é–¢ã®å¼·ã•", f"{color} {strength}")
                
                # ç›¸é–¢ã®æ–¹å‘ã¨ ãƒ‡ãƒ¼ã‚¿æ•°
                direction = "æ­£ã®ç›¸é–¢" if correlation > 0 else "è² ã®ç›¸é–¢"
                st.metric("ç›¸é–¢ã®æ–¹å‘", direction)
                
                st.metric("åˆ†æãƒ‡ãƒ¼ã‚¿æ•°", f"{len(pair_data):,}ä»¶")
                
                if idx < len(strong_correlations[:3]) - 1:
                    st.markdown("---")
    
    # å…¨ãƒšã‚¢ã®ç›¸é–¢ä¿‚æ•°ä¸€è¦§è¡¨ç¤º
    st.subheader("ğŸ“‹ å…¨ãƒšã‚¢ç›¸é–¢ä¿‚æ•°ä¸€è¦§")
    correlation_list = []
    for i in range(len(selected_vars)):
        for j in range(i+1, len(selected_vars)):
            correlation_list.append({
                'é …ç›®1': numerical_options.get(selected_vars[i]),
                'é …ç›®2': numerical_options.get(selected_vars[j]),
                'ç›¸é–¢ä¿‚æ•°': f"{corr_matrix.iloc[i, j]:.4f}"
            })
    
    correlation_df = pd.DataFrame(correlation_list)
    correlation_df = correlation_df.sort_values('ç›¸é–¢ä¿‚æ•°', key=lambda x: x.astype(float).abs(), ascending=False)
    st.dataframe(correlation_df, width='stretch', height=300)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ“Š AniList ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼
    st.sidebar.title("ğŸ“‹ ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    
    # ã‚¢ãƒ‹ãƒ¡é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.sidebar.markdown("## ğŸ¬ ã‚¢ãƒ‹ãƒ¡é–¢é€£")
    anime_menu = st.sidebar.radio(
        "åˆ†æé …ç›®ã‚’é¸æŠ:",
        ["ã‚¿ã‚¤ãƒˆãƒ«", "ã‚­ãƒ£ãƒ©", "å£°å„ª", "ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¹ã‚¿ã‚¸ã‚ª", "åŸä½œ", "ã‚¸ãƒ£ãƒ³ãƒ«", "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"],
        key="anime_menu"
    )
    
    # ãƒãƒ³ã‚¬é–¢é€£ã‚»ã‚¯ã‚·ãƒ§ãƒ³  
    st.sidebar.markdown("## ğŸ“š ãƒãƒ³ã‚¬é–¢é€£")
    manga_menu = st.sidebar.radio(
        "åˆ†æé …ç›®ã‚’é¸æŠ:",
        ["ã‚¿ã‚¤ãƒˆãƒ«", "ã‚­ãƒ£ãƒ©", "ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¸ãƒ£ãƒ³ãƒ«", "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"],
        key="manga_menu"
    )
    
    # é¸æŠã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
    if anime_menu == "ã‚¿ã‚¤ãƒˆãƒ«":
        # æ—¢å­˜ã®ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚¤ãƒˆãƒ«åˆ†æï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€åŸºç¤çµ±è¨ˆã€ç›¸é–¢åˆ†æï¼‰
        data = load_anime_data()
        if data is None:
            st.error("ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2, tab3 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ", "ç›¸é–¢åˆ†æ"])
        
        with tab1:
            show_ranking_tab(data, "ã‚¢ãƒ‹ãƒ¡")
        
        with tab2:
            show_statistics_tab(data, "ã‚¢ãƒ‹ãƒ¡")
        
        with tab3:
            show_scatter_tab(data, "ã‚¢ãƒ‹ãƒ¡")
    
    elif anime_menu == "ã‚­ãƒ£ãƒ©":
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ†æ
        data = load_character_data()
        if data is None:
            st.error("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ"])
        
        with tab1:
            show_character_ranking_tab(data)
        
        with tab2:
            show_character_statistics_tab(data)
    
    elif anime_menu == "å£°å„ª":
        # å£°å„ªåˆ†æ
        data = load_voiceactor_data()
        if data is None:
            st.error("å£°å„ªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ"])
        
        with tab1:
            show_voiceactor_ranking_tab(data)
        
        with tab2:
            show_voiceactor_statistics_tab(data)
    
    elif anime_menu == "ã‚¹ã‚¿ãƒƒãƒ•":
        # ã‚¹ã‚¿ãƒƒãƒ•åˆ†æ
        data = load_staff_data()
        if data is None:
            st.error("ã‚¹ã‚¿ãƒƒãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ"])
        
        with tab1:
            show_staff_ranking_tab(data)
        
        with tab2:
            show_staff_statistics_tab(data)
    
    elif anime_menu == "ã‚¹ã‚¿ã‚¸ã‚ª":
        # ã‚¹ã‚¿ã‚¸ã‚ªåˆ†æ
        data = load_studios_data()
        if data is None:
            st.error("ã‚¹ã‚¿ã‚¸ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ"])
        
        with tab1:
            show_studios_ranking_tab(data)
        
        with tab2:
            show_studios_statistics_tab(data)
    
    elif manga_menu == "ã‚¿ã‚¤ãƒˆãƒ«":
        # ãƒãƒ³ã‚¬ã‚¿ã‚¤ãƒˆãƒ«åˆ†æ
        data = load_manga_data()
        if data is None:
            st.error("ãƒãƒ³ã‚¬ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ¡ã‚¤ãƒ³ç”»é¢ã®ã‚¿ãƒ–åˆ†é›¢
        tab1, tab2, tab3 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "åŸºç¤çµ±è¨ˆ", "ç›¸é–¢åˆ†æ"])
        
        with tab1:
            show_ranking_tab(data, "æ¼«ç”»")
        
        with tab2:
            show_statistics_tab(data, "æ¼«ç”»")
        
        with tab3:
            show_scatter_tab(data, "æ¼«ç”»")
    
    else:
        # ãã®ä»–ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰
        if anime_menu in ["å£°å„ª", "ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¹ã‚¿ã‚¸ã‚ª", "åŸä½œ", "ã‚¸ãƒ£ãƒ³ãƒ«", "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"]:
            st.header(f"ğŸ¬ ã‚¢ãƒ‹ãƒ¡ {anime_menu} åˆ†æ")
            st.info(f"ã‚¢ãƒ‹ãƒ¡ã®{anime_menu}åˆ†ææ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")
            
        elif manga_menu in ["ã‚­ãƒ£ãƒ©", "ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¸ãƒ£ãƒ³ãƒ«", "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"]:
            st.header(f"ğŸ“š ãƒãƒ³ã‚¬ {manga_menu} åˆ†æ")
            st.info(f"ãƒãƒ³ã‚¬ã®{manga_menu}åˆ†ææ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")

if __name__ == "__main__":
    main()