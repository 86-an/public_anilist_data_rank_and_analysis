import requests
import time
import json

# ä¿å­˜ç”¨ãƒªã‚¹ãƒˆï¼ˆå–å¾—ã—ãŸã™ã¹ã¦ã®ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ï¼‰
all_anime_data = []

url = "https://graphql.anilist.co"

query = """
query ($page: Int) {
  Page(page: $page, perPage: 50) {
    pageInfo {
      hasNextPage
    }
    media(type: MANGA, sort: POPULARITY_DESC) {
      id
      title {
        romaji
        native
      }
      format
      startDate {
        year
        month
        day
      }
      favourites
      meanScore
      popularity
      countryOfOrigin
      genres
      source
      description
      characters(sort: FAVOURITES_DESC) {
        edges {
          node {
            id
            name {
              userPreferred
              native
            }
            favourites
          }
        }
      }
      staff(sort: FAVOURITES_DESC) {
        edges {
          role
          node {
            id
            name {
              userPreferred
              native
            }
            favourites
          }
        }
      }
    }
  }
}
"""

import re

def sanitize_description(json_text):
    import re
    # descriptionã®å€¤ã‚’ç©ºæ–‡å­—ã«ç½®ãæ›ãˆã‚‹ï¼ˆç°¡æ˜“çš„ãªæ­£è¦è¡¨ç¾ï¼‰
    return re.sub(r'"description"\s*:\s*"[^"]*?(?<!\\)"', '"description": ""', json_text)

def fetch_anime(page):
    """æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ç•ªå·ã®ã‚¢ãƒ‹ãƒ¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ï¼ˆäººæ°—é †ï¼‰"""
    variables = {"page": page}
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
    }

    try:
        response = requests.post(url, json={"query": query, "variables": variables}, headers=headers)
        response.raise_for_status()

        # JSONãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†ï¼ˆdescriptionã‚¨ãƒ©ãƒ¼å¯¾ç­–ä»˜ãï¼‰
        raw_text = response.text
        try:
            data = json.loads(raw_text)
        except json.JSONDecodeError:
            print(f"âš ï¸ JSONã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€descriptionã‚’ç©ºæ¬„ã«ã—ã¦å†è©¦è¡Œã—ã¾ã™")
            raw_text_sanitized = sanitize_description(raw_text)
            try:
                data = json.loads(raw_text_sanitized)
            except json.JSONDecodeError as e:
                print(f"âŒ å†è©¦è¡Œå¤±æ•—: {e}")
                with open(f"error_page_{page}.txt", "w", encoding="utf-8") as f:
                    f.write(raw_text)
                return None

        if 'errors' in data:
            print(f"APIã‹ã‚‰ã®ã‚¨ãƒ©ãƒ¼: {data['errors']}")
            return None

        return data

    except requests.exceptions.RequestException as e:
        print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™å¯¾ç­–
request_count = 0

# ãƒšãƒ¼ã‚¸ã‚’å›ã—ã¦å–å¾—
page = 1
is_last_page = False

print("--- äººæ°—é †ã§ã‚¢ãƒ‹ãƒ¡æƒ…å ±ã‚’å–å¾—é–‹å§‹ ---")

while not is_last_page:
    data = fetch_anime(page)

    if data and 'data' in data and data['data']['Page']['media']:
        print(f"âœ… Page {page} å–å¾—å®Œäº†")
        all_anime_data.extend(data['data']['Page']['media'])

        if not data['data']['Page']['pageInfo']['hasNextPage']:
            is_last_page = True
        page += 1
    else:
        is_last_page = True
        print(f"âš ï¸ Page {page} ã§ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    request_count += 1
    if request_count % 30 == 0:
        print("â³ 30ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ°é”ã€60ç§’ä¼‘æ­¢ä¸­...")
        time.sleep(60)
    else:
        time.sleep(2)

print("å…¨ã¦ã®äººæ°—é †ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# ğŸ”½ JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
with open("anilist_rank_data_analysis_popular_all_manga.json", "w", encoding="utf-8") as f:
    json.dump(all_anime_data, f, ensure_ascii=False, indent=2)

print("âœ… anilist_rank_data_analysis_popular_all_manga.json ã«ä¿å­˜å®Œäº†")